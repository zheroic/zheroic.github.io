<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>hadoop离线计算-2：Hadoop分布式文件存储系统 | zh小企鹅</title><meta name="description" content="hadoop离线计算-2：Hadoop分布式文件存储系统"><meta name="keywords" content="hadoop"><meta name="author" content="zheroic"><meta name="copyright" content="zheroic"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon1.png"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="canonical" href="https://zheroic.github.io/2019/09/27/hadoop-2/"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:title" content="hadoop离线计算-2：Hadoop分布式文件存储系统"><meta name="twitter:description" content="hadoop离线计算-2：Hadoop分布式文件存储系统"><meta name="twitter:image" content="https://pic.superbed.cn/item/5d8d5e78451253d17830baa7.png"><meta property="og:type" content="article"><meta property="og:title" content="hadoop离线计算-2：Hadoop分布式文件存储系统"><meta property="og:url" content="https://zheroic.github.io/2019/09/27/hadoop-2/"><meta property="og:site_name" content="zh小企鹅"><meta property="og:description" content="hadoop离线计算-2：Hadoop分布式文件存储系统"><meta property="og:image" content="https://pic.superbed.cn/item/5d8d5e78451253d17830baa7.png"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="prev" title="数据科学导论-1：探索性数据分析和数据预处理" href="https://zheroic.github.io/2019/10/08/data-science-1/"><link rel="next" title="hadoop离线计算-1:初识Hadoop" href="https://zheroic.github.io/2019/09/27/hadoop-1/"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css"><script src="https://cdn.jsdelivr.net/gh/upupming/gitalk@36368e5dffd049e956cdbbd751ff96c28d8255cf/dist/gitalk.min.js"></script><script src="https://cdn.jsdelivr.net/npm/blueimp-md5@2.10.0/js/md5.min.js"></script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  highlight_copy: 'true',
  highlight_lang: 'true',
  highlight_shrink: 'false',
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    title: '添加书签',
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天'

  
}</script><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head><body><div id="web_bg"></div><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Hadoop分布式文件存储系统"><span class="toc-text">Hadoop分布式文件存储系统</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#hadoop简介"><span class="toc-text">hadoop简介</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#官方定义："><span class="toc-text">官方定义：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#基本原理："><span class="toc-text">基本原理：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hadoop实现原理"><span class="toc-text">Hadoop实现原理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#基本原理：-1"><span class="toc-text">基本原理：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#优点："><span class="toc-text">优点：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#缺点："><span class="toc-text">缺点：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS实现原理-namenode和datanode"><span class="toc-text">HDFS实现原理-namenode和datanode</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS实现原理"><span class="toc-text">HDFS实现原理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#数据块"><span class="toc-text">数据块:</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#优点：-1"><span class="toc-text">优点：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#NameNode"><span class="toc-text">NameNode</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#功能"><span class="toc-text">功能</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Secondary-NameNode"><span class="toc-text">Secondary NameNode</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#功能-1"><span class="toc-text">功能</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DataNode"><span class="toc-text">DataNode</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#功能-2"><span class="toc-text">功能</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#复制因子-block"><span class="toc-text">复制因子(block)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#机架感知"><span class="toc-text">机架感知</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS读写流程-写数据"><span class="toc-text">HDFS读写流程-写数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS读写流程-写数据之建立流水线（pipline）"><span class="toc-text">HDFS读写流程-写数据之建立流水线（pipline）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS读写流程-写数据之数据复制（data-Streaming"><span class="toc-text">HDFS读写流程-写数据之数据复制（data Streaming)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS读写流程-写数据之关闭流水线"><span class="toc-text">HDFS读写流程-写数据之关闭流水线</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS读写流程-多个Block同时写入"><span class="toc-text">HDFS读写流程-多个Block同时写入</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS读写流程-文件读取"><span class="toc-text">HDFS读写流程-文件读取</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS-filesystem-shell"><span class="toc-text">HDFS filesystem shell</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#cat"><span class="toc-text">[cat]</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#appendToFile"><span class="toc-text">[appendToFile]</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#chgrp"><span class="toc-text">[chgrp]</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#chmod"><span class="toc-text">[chmod]</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#chown"><span class="toc-text">[chown]</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#copyFromLocal"><span class="toc-text">[copyFromLocal]</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#copyToLocal"><span class="toc-text">[copyToLocal]</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#count"><span class="toc-text">[count]</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cp"><span class="toc-text">[cp]</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#df"><span class="toc-text">[df]</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#expunge"><span class="toc-text">[expunge]</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#get"><span class="toc-text">[get]</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#getmerge"><span class="toc-text">[getmerge]</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ls"><span class="toc-text">[ls]</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#lsr"><span class="toc-text">[lsr]</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#mkdir"><span class="toc-text">[mkdir]</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#mv"><span class="toc-text">[mv]</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#put"><span class="toc-text">[put]</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#rm"><span class="toc-text">[rm]</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#setrep"><span class="toc-text">[setrep]</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#stat"><span class="toc-text">[stat]</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#tail"><span class="toc-text">[tail]</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#text"><span class="toc-text">[text]</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#touchz"><span class="toc-text">[touchz]</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#truncate"><span class="toc-text">[truncate]</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#usage"><span class="toc-text">[usage]</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#find"><span class="toc-text">[find]</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#getfacl"><span class="toc-text">[getfacl]</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS-dfsadmin"><span class="toc-text">HDFS dfsadmin</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS-DistCp"><span class="toc-text">HDFS DistCp</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS-getConf"><span class="toc-text">HDFS getConf</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS-oev"><span class="toc-text">HDFS oev</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS-oiv"><span class="toc-text">HDFS oiv</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS-fsck"><span class="toc-text">HDFS fsck</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS-balancer"><span class="toc-text">HDFS balancer</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS-快照"><span class="toc-text">HDFS 快照</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#总结"><span class="toc-text">总结</span></a></li></ol></li></ol></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://pic.superbed.cn/item/5d8d5e78451253d17830baa7.png)"><div id="page-header"><span class="pull-left"> <a class="blog_title" id="site-name" href="/">zh小企鹅</a></span><div class="open toggle-menu pull-right"><div class="menu-icon-first"></div><div class="menu-icon-second"></div><div class="menu-icon-third"></div></div><div class="menu_mask"></div><span class="pull-right menus"><div class="mobile_author_icon"><img class="lozad avatar_img" src="https://pic.superbed.cn/item/5da4889d451253d1788ae932.png" onerror="onerror=null;src='/img/friend_404.gif'"></div><div class="mobile_post_data"><div class="mobile_data_item text-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">13</div></a></div></div><div class="mobile_data_item text-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">7</div></a></div></div><div class="mobile_data_item text-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">4</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/contact/"><i class="fa-fw fa fa-comments"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于我</span></a></div><script>document.body.addEventListener('touchstart', function(){ });</script></div></span><span class="pull-right"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i><span> 搜索</span></a></span></div><div id="post-info"><div id="post-title"><div class="posttitle">hadoop离线计算-2：Hadoop分布式文件存储系统</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 发表于 2019-09-27<span class="post-meta__separator">|</span><i class="fa fa-history" aria-hidden="true"></i> 更新于 2019-10-09</time><span class="post-meta__separator mobile_hidden">|</span><span class="mobile_hidden"><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/大数据/">大数据</a></span><div class="post-meta-wordcount"><span>字数总计: </span><span class="word-count">6.4k</span><span class="post-meta__separator">|</span><span>阅读时长: 23 分钟</span><span class="post-meta__separator">|</span><span>阅读量: </span><span id="busuanzi_value_page_pv"></span></div></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><h1 id="Hadoop分布式文件存储系统"><a href="#Hadoop分布式文件存储系统" class="headerlink" title="Hadoop分布式文件存储系统"></a>Hadoop分布式文件存储系统</h1><h2 id="hadoop简介"><a href="#hadoop简介" class="headerlink" title="hadoop简介"></a>hadoop简介</h2><h3 id="官方定义："><a href="#官方定义：" class="headerlink" title="官方定义："></a>官方定义：</h3><p>分布式存储系统HDFS（Hadoop Distributed File System）。<br>其实就是一个文件系统，类似于linux的文件系统。有目录，目录下可以存储文件。但它又是一个分布式的文件系统。</p>
<h3 id="基本原理："><a href="#基本原理：" class="headerlink" title="基本原理："></a>基本原理：</h3><ul>
<li>将文件切分成等大的数据块。分别存储到多台机器上。</li>
<li>每个数据块存在多个备份。</li>
<li>将数据切分、容错、负载均衡等功能透明化。</li>
<li>可将HDFS看成是一个巨大、具有容错性的磁盘。</li>
</ul>
<h2 id="Hadoop实现原理"><a href="#Hadoop实现原理" class="headerlink" title="Hadoop实现原理"></a>Hadoop实现原理</h2><h3 id="基本原理：-1"><a href="#基本原理：-1" class="headerlink" title="基本原理："></a>基本原理：</h3><ul>
<li>将文件切分成等大的数据块。分别存储到多台机器上。</li>
<li>每个数据块存在多个备份。</li>
<li>将数据切分、容错、负载均衡等功能透明化。</li>
<li>可将HDFS看成是一个巨大、具有容错性的磁盘。</li>
</ul>
<h3 id="优点："><a href="#优点：" class="headerlink" title="优点："></a>优点：</h3><ul>
<li>处理超大文件</li>
<li>流式的数据访问</li>
<li>运行于廉价的商业机器集群上</li>
</ul>
<h3 id="缺点："><a href="#缺点：" class="headerlink" title="缺点："></a>缺点：</h3><ul>
<li>不适合存储大量小文件</li>
<li>不适合低延迟数据访问</li>
<li>不支持多用户写入及任意修改文件</li>
</ul>
<p><img alt="Hadoop实现原理" data-src="https://pic.superbed.cn/item/5d8d6021451253d17830f971.png" class="lozad"></p>
<h2 id="HDFS实现原理-namenode和datanode"><a href="#HDFS实现原理-namenode和datanode" class="headerlink" title="HDFS实现原理-namenode和datanode"></a>HDFS实现原理-namenode和datanode</h2><p>HDFS集群有两类节点，并以管理者-工作者模式运行，即一个namenode(管理者)和多个datanode(工作者)。 </p>
<ul>
<li><strong>namenode</strong>： namenode管理文件系统的命名空间。它维护着文件系统树及整棵树内所有的文件和目录。这些信息以两个文件形式永久保存在本地磁盘上:命名空间镜像文件(fs-image)和编辑日志(edit-logs)文件。namenode也记录着每个文件中各个块所在的数据节点信息，但它并不永久保存块的位置信息，因为这些信息会在系统启动时由数据节点重建。 </li>
<li><strong>datanode</strong>： 是文件系统的工作节点。它们根据需要存储并检索数据块(受客户端或namenode调度)，并且定期向namenode 发送它们所存储的块的列表。 </li>
<li><strong>客户端(Client)</strong>： Client代表用户通过namenode和datanode访问整个文件系统。客户端提供一个类似于POSIX（可移植操作系统界面）的文件系统接口，因此用户在编程时无需知道namenode和datanode也可实现其功能。</li>
<li><strong>Namenode备份机制</strong>：<ul>
<li>文件系统元数据持久状态的文件备份：一般的配置是，将持久状态写入本地磁盘的同时，写入一个远程挂载的网络文件系统 (NFS)。</li>
<li>nameNodeHA。</li>
</ul>
</li>
</ul>
<h2 id="HDFS实现原理"><a href="#HDFS实现原理" class="headerlink" title="HDFS实现原理"></a>HDFS实现原理</h2><h3 id="数据块"><a href="#数据块" class="headerlink" title="数据块:"></a>数据块:</h3><ul>
<li>每个磁盘都有默认的数据块大小，这是磁盘进行数据读/写的最小单位。构建于单个磁盘之上的文件系统通过磁盘块来管理该文件系统中的块，该文件系统块的大小可以是磁盘块的整数倍。</li>
<li>HDFS同样也有块 (block)的概念，但是大得多，默认为128 MB 。与单一磁盘上的文件系统相 似，HDFS上的文件也被划分为块大小的多个分块 (chunk) ，作为独立的存储单元。但与其他 文件系统不同的是，HDFS中小于一个块大小的文件不会占据整个块的空间。<br><img alt="example" data-src="https://pic.superbed.cn/item/5d8d6331451253d178319ea2.png" class="lozad"></li>
</ul>
<h3 id="优点：-1"><a href="#优点：-1" class="headerlink" title="优点："></a>优点：</h3><ul>
<li>一个大文件不用存储于整块磁盘上，可以分布式存储。</li>
<li>使用块抽象而非整个文件作为存储单元，大大简化了存储子系统的设计。这对于故障种类繁 多的分布式系统尤为重要。 </li>
</ul>
<p>与磁盘管理相似，HDFS提供了fsck命令可以显示块信息：<br> hdfs fsck / -files -blocks</p>
<h3 id="NameNode"><a href="#NameNode" class="headerlink" title="NameNode"></a>NameNode</h3><ul>
<li>NameNode是HDFS架构中的主节点。</li>
</ul>
<h4 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h4><ul>
<li>管理各个从节点的状态(DataNode)。 </li>
<li>记录存储在HDFS上的所有数据的元数据信息。例如：block存储的位置，文件大小，文件权限， 文件层级等等。这些信息以两个文件形式永久保存在本地磁盘上。 <ul>
<li><strong>命名空间镜像文件(FsImage)</strong>: fsimage是HDFS文件系统存于硬盘中的元数据检查点，里面记录 了自最后一次检查点之前HDFS文件系统中所有目录和文件的序列化信息 </li>
<li><strong>编辑日志(edit-logs)文件</strong>：保存了自最后一次检查点之后所有针对HDFS文件系统的操作，比如： 增加文件、重命名文件、删除目录等等。 </li>
</ul>
</li>
<li>记录了存储在HDFS上文件的所有变化，例如文件被删除，namenode会记录到editlog中。 </li>
<li>接受DataNode的心跳和各个datanode上的block报告信息，确保DataNode是否存活。</li>
<li>负责处理所有块的复制因子。</li>
<li>如果DataNode节点宕机，NameNode会选择另外一个DataNode均衡复制因子，并做负载均衡。<br>参考：<a href="http://hadoop.apache.org/docs/r2.6.0/hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html" target="_blank" rel="noopener">http://hadoop.apache.org/docs/r2.6.0/hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html</a></li>
</ul>
<h3 id="Secondary-NameNode"><a href="#Secondary-NameNode" class="headerlink" title="Secondary NameNode"></a>Secondary NameNode</h3><ul>
<li>SNameNode是NameNode的助手，不要将其理解成是NameNode的备份。Secondary NameNode 的整个目的在HDFS中提供一个Checkpoint Node，所以也被叫做checkpoint node。 </li>
</ul>
<p><strong>不与NameNode部署在同一节点，为了减少NameNode负担</strong></p>
<h4 id="功能-1"><a href="#功能-1" class="headerlink" title="功能"></a>功能</h4><ul>
<li>定时的从NameNode获取EditLogs,并更新到FsImage上。</li>
<li>一旦它有新的fsimage文件，它将其拷贝回NameNode上，NameNode在下次重启时会使用这个新的fsimage文件，从而减少重启的时间。<br><img alt="Hadoop实现原理-1" data-src="https://pic.superbed.cn/item/5d8d65bd451253d178323a5a.png" class="lozad"></li>
</ul>
<p><font color="red">注意：关于NameNode是什么时候将改动写到editlogs中的？这个操作实际上是由DataNode的写操作触发的，当我们往DataNode写文件时，DataNode会跟NameNode通信，告诉NameNode什么文件的第几个block放在它那里，NameNode这个时候会将这些元数据信息写到editlogs文件中</font></p>
<h3 id="DataNode"><a href="#DataNode" class="headerlink" title="DataNode"></a>DataNode</h3><ul>
<li>DataNode是HDFS架构的从节点，管理各自节点的Block信息。 </li>
</ul>
<h4 id="功能-2"><a href="#功能-2" class="headerlink" title="功能"></a>功能</h4><ul>
<li>多个数据实际是存储到DataNode上面。</li>
<li>DataNode分别运行在独立的节点上。</li>
<li>DataNode执行客户端级别的读写请求。客户端直接和DataNode交互</li>
<li>向NameNode发送心跳(默认是3s)，报告各自节点的健康状况。</li>
</ul>
<h3 id="复制因子-block"><a href="#复制因子-block" class="headerlink" title="复制因子(block)"></a>复制因子(block)</h3><ul>
<li>HDFS为我们提供了可靠的存储，就是因为这个复制因子。默认复制因子是3。<br><img alt="复制因子" data-src="https://pic.superbed.cn/item/5d8d6927451253d178330b85.png" class="lozad"></li>
</ul>
<p><strong>注意： DataNode会定时发送心跳给NameNode，汇报各自节点的Block 信息。NameNode收集到这些信息后，会对超出复制因子的Block删除，复制因子不足的Block做添加。</strong></p>
<h3 id="机架感知"><a href="#机架感知" class="headerlink" title="机架感知"></a>机架感知</h3><p><img alt="机架感知" data-src="https://pic.superbed.cn/item/5d8d69e1451253d178333608.png" class="lozad"></p>
<ul>
<li>分布式的集群通常包含非常多的机器，由于受到机架槽位和交换机网口的限制，通常大型的分布式集群都会跨好几个机架，由多个机架上的机器共同组成一个分布式集群。机架内的机器之间的网络速度通常都会高于跨机架机器之间的网络速度，并且机架之间机器的网络通信通常受到上层交换机间网络带宽的限制。</li>
</ul>
<h2 id="HDFS读写流程-写数据"><a href="#HDFS读写流程-写数据" class="headerlink" title="HDFS读写流程-写数据"></a>HDFS读写流程-写数据</h2><p>假设我们有一个example.txt的文件，大小为248M。要将其写入到HDFS中。假设我们使用HDFS设置的块大小为128M(默认值)。那么client会将此文件拆分成两个块。第一个块是120MB(BlOCK 1),第二个块是120MB(BLOCK 2)。<br><img alt="example" data-src="https://pic.superbed.cn/item/5d8d6a6b451253d178335aab.png" class="lozad"></p>
<ul>
<li>首先，client请求namenode，要将多个块写入到HDFS。例如这里的Block A和Block B。</li>
<li>NameNode会给client赋予写权限，并为client提供可以写入数据的DataNode的IP地址。Namenode在选择可写入数据的dataNode的规则是结合了DN的健康状态、复制因子、机架感知等因素随机选择的DN。假如复制因子是3(默认值），那么会为每个block返回三个IP地址。例如NN为client提供了以下的IP地址列表。<br>Block A, list A = {IP of DataNode 1, IP of DataNode 4, IP of DataNode 6}<br>Block B, set B = {IP of DataNode 3, IP of DataNode 7, IP of DataNode 9} </li>
<li>整体的数据复制流程分一下三个阶段。1.流水线建立；2.复制数据；3.关闭流水线；<br><img alt="数据复制流程" data-src="https://pic.superbed.cn/item/5d8d6b4c451253d1783396f9.png" class="lozad"></li>
</ul>
<h2 id="HDFS读写流程-写数据之建立流水线（pipline）"><a href="#HDFS读写流程-写数据之建立流水线（pipline）" class="headerlink" title="HDFS读写流程-写数据之建立流水线（pipline）"></a>HDFS读写流程-写数据之建立流水线（pipline）</h2><p><img alt="建立流水线" data-src="https://pic.superbed.cn/item/5d8d6c82451253d17833e489.png" class="lozad"></p>
<ul>
<li>在写入数据之前，client首先要确认namenode提供的ip列表是否准备好了接收数据。Client通过连接各个块的ip列表来为每个块创建流水线。</li>
<li>我们以Block1为例。<br>For Block A, list A = {<br>IP of DataNode 1,<br>IP of DataNode 4,<br>IP of DataNode 6}</li>
</ul>
<h2 id="HDFS读写流程-写数据之数据复制（data-Streaming"><a href="#HDFS读写流程-写数据之数据复制（data-Streaming" class="headerlink" title="HDFS读写流程-写数据之数据复制（data Streaming)"></a>HDFS读写流程-写数据之数据复制（data Streaming)</h2><p><img alt="数据复制" data-src="https://pic.superbed.cn/item/5d8d6da9451253d178343d0d.png" class="lozad"></p>
<ul>
<li>流水线建立好之后，client将会向流水线中写入数据。</li>
<li>注意：Client只会将block A向DN1复制。其他节点复制是在DN之间完成的。</li>
</ul>
<h2 id="HDFS读写流程-写数据之关闭流水线"><a href="#HDFS读写流程-写数据之关闭流水线" class="headerlink" title="HDFS读写流程-写数据之关闭流水线"></a>HDFS读写流程-写数据之关闭流水线</h2><p><img alt="关闭流水线" data-src="https://pic.superbed.cn/item/5d8d6e22451253d178345cf9.png" class="lozad"></p>
<ul>
<li>当数据复制到所有的DN完成之后，按照ip地址列表相反的方向，依次反馈写入成功的信息。</li>
<li>DN6-&gt;DN4-&gt;DN1</li>
<li>DN1将确认信息反馈给client， client再将确认信息反馈给NN，NN更新元数据信息，client关<br>闭pipline。</li>
</ul>
<h2 id="HDFS读写流程-多个Block同时写入"><a href="#HDFS读写流程-多个Block同时写入" class="headerlink" title="HDFS读写流程-多个Block同时写入"></a>HDFS读写流程-多个Block同时写入</h2><p><img alt="多个Block同时写入" data-src="https://pic.superbed.cn/item/5d8d6edb451253d17834888c.png" class="lozad"></p>
<ul>
<li>Block A和Block B的写入是并行进行的。</li>
<li>Block A:1A-&gt;2A-&gt;3A</li>
<li>Block B:1B-&gt;2B-&gt;3B-&gt;4B-&gt;5B-&gt;6B</li>
</ul>
<h2 id="HDFS读写流程-文件读取"><a href="#HDFS读写流程-文件读取" class="headerlink" title="HDFS读写流程-文件读取"></a>HDFS读写流程-文件读取</h2><p><img alt="文件读取" data-src="https://pic.superbed.cn/item/5d8d6f98451253d17834baa5.png" class="lozad"></p>
<ul>
<li>Client请求namenode要读取exaple.txt文件。</li>
<li>NN根据自己的元数据信息，反馈给client一个DataNode的列表(存储Block A和B)。</li>
<li>Client连接DN，读取BlockA,Block B的数据。</li>
<li>Client合并block A和Block B的数据。</li>
</ul>
<h2 id="HDFS-filesystem-shell"><a href="#HDFS-filesystem-shell" class="headerlink" title="HDFS filesystem shell"></a>HDFS filesystem shell</h2><h3 id="cat"><a href="#cat" class="headerlink" title="[cat]"></a>[cat]</h3><p>使用方法：hadoop fs -cat URI [URI …]<br>说明：将路径指定文件的内容输出到<em>stdout</em></p>
<ul>
<li>hadoop fs -cat /dataAnalysis/duliming/input/mapreduceInput/wordCount.txt </li>
<li>hadoop fs -cat file:///usr/local/usrJar/duliming/DataAnalysis/output/AEP/20161203094310.csv</li>
</ul>
<h3 id="appendToFile"><a href="#appendToFile" class="headerlink" title="[appendToFile]"></a>[appendToFile]</h3><p>使用方法：hadoop fs -appendToFile <localsrc> … <dst><br>说明：添加(追加)一个或多个源文件到目标文件中。或者将标准输入中的数据写入目标文件。 </dst></localsrc></p>
<ul>
<li>hadoop fs -appendToFile - /dataAnalysis/duliming/output/stdinMergeFile.csv </li>
<li>hadoop fs -appendToFile /usr/local/usrJar/duliming/pcbin/pcbin_month/000002_0 /usr/local/usrJar/duliming/pcbin/pcbin_month/000003_0 /dataAnalysis/duliming/output/mergeFile.csv</li>
</ul>
<h3 id="chgrp"><a href="#chgrp" class="headerlink" title="[chgrp]"></a>[chgrp]</h3><p>grp [-R] GROUP URI [URI …] </p>
<ul>
<li>hadoop fs -chgrp hdfs /dataAnalysis/duliming/output/mergeFile.csv</li>
</ul>
<h3 id="chmod"><a href="#chmod" class="headerlink" title="[chmod]"></a>[chmod]</h3><p>使用方法：hadoop fs -chmod [-R] &lt;MODE[,MODE]… | OCTALMODE&gt; URI [URI …] 说明：修改文件权限。-R表示是否递归。修改者必须拥有该目录权限，或者是拥有者的父用户。 Example:<br>hadoop fs -chmod 777 /dataAnalysis/duliming/output/mergeFile.csv</p>
<h3 id="chown"><a href="#chown" class="headerlink" title="[chown]"></a>[chown]</h3><p>使用方法：hadoop fs -chown [-R] [OWNER][:[GROUP]] URI [URI ] 说明：修改文件拥有者。修改者必须拥有该文件或者是其父用户。-R表示递归。<br>Example: hadoop fs -chown hdfs /dataAnalysis/duliming/output/mergeFile.csv</p>
<h3 id="copyFromLocal"><a href="#copyFromLocal" class="headerlink" title="[copyFromLocal]"></a>[copyFromLocal]</h3><p>使用方法：hadoop fs -copyFromLocal <localsrc> URI 说明：拷贝本地文件到HDFS。类似于put命令，但可以拷贝目录。-f参数表示覆盖原来已存在目录。<br>Example: hadoop fs -copyFromLocal /usr/local/usrJar/duliming/DataAnalysis/output/AEP /dataAnalysis/duliming/output/</localsrc></p>
<h3 id="copyToLocal"><a href="#copyToLocal" class="headerlink" title="[copyToLocal]"></a>[copyToLocal]</h3><p>使用方法：hadoop fs -copyToLocal [-ignorecrc] [-crc] URI <localdst> 说明：拷贝HDFS文件到本地，类似于get命令，但可以拷贝目录。<br>Example: Hadoop fs –copyToLocal/dataAnalysis/duliming/output/ /usr/local/usrJar/duliming/DataAnalysis/output/AEP</localdst></p>
<h3 id="count"><a href="#count" class="headerlink" title="[count]"></a>[count]</h3><p>使用方法：hadoop fs -count [-q] [-h] [-v] <paths> 说明：统计目录下文件数，空间占用情况。 -h:输出格式化后的信息。 -v：输出表头<br>Example: hadoop fs -count -q -h -v /dataAnalysis/duliming/output<br><img alt="count" data-src="https://pic.superbed.cn/item/5d8d7210451253d178356356.png" class="lozad"></paths></p>
<h3 id="cp"><a href="#cp" class="headerlink" title="[cp]"></a>[cp]</h3><p>使用方法：hadoop fs -cp [-f] [-p | -p[topax]] URI [URI …] <dest><br>说明：将文件从源路径复制到目标路径。这个命令允许有多个源路径，此时目标路径必须是一个目录。 -f 如果目标 目录已存在，则覆盖之前的目录。<br>Example: hadoop fs -cp -f /dataAnalysis/duliming/output/wordcount/dataAnalysis/duliming/output/wordcount1</dest></p>
<h3 id="df"><a href="#df" class="headerlink" title="[df]"></a>[df]</h3><p>使用方法：hadoop fs -df [-h] URI [URI …] 显示目录空闲空间，-h：转换为更加易读的方式，比如67108864用64M代替。<br>Example: hadoop fs -df -h /dataAnalysis</p>
<h3 id="expunge"><a href="#expunge" class="headerlink" title="[expunge]"></a>[expunge]</h3><p>使用方法： hadoop fs –expunge<br>说明：清空回收站,hdfs默认是没有开启回收站功能的，需要配置中开启。</p>
<h3 id="get"><a href="#get" class="headerlink" title="[get]"></a>[get]</h3><p>使用方法：hadoop fs -get [-ignorecrc] [-crc] <src> <localdst><br>说明：复制文件到本地文件系统。可用-ignorecrc选项复制CRC校验失败的文件。使用-crc选项复制文件以及CRC信息。<br>Example: hadoop fs -get /user/hadoop/file localfile hadoop fs -get hdfs://host:port/user/hadoop/file localfile</localdst></src></p>
<h3 id="getmerge"><a href="#getmerge" class="headerlink" title="[getmerge]"></a>[getmerge]</h3><p>使用方法：hadoop fs -getmerge <src> <localdst> [addnl]<br>接受一个源目录和一个目标文件作为输入，并且将源目录中所有的文件连接成本地目标文件。addnl是可选的，用于指定在每个文件结尾添加一个换行符。</localdst></src></p>
<h3 id="ls"><a href="#ls" class="headerlink" title="[ls]"></a>[ls]</h3><p>使用方法：hadoop fs -ls <args><br>说明：如果是文件，则按照如下格式返回文件信息： 文件名 &lt;副本数&gt; 文件大小 修改日期 修改时间 权限 用户ID 组ID 如果是目录，则返回它直接子文件的一个列表，就像在Unix中一样。目录返回列表的信息如下： 目录名 </args></p><dir> 修改日期 修改时间 权限 用户ID 组ID<br>Example: hadoop fs -ls /user/hadoop/file1 /user/hadoop/file2 hdfs://host:port/user/hadoop/dir1 /nonexistentfile</dir><p></p>
<h3 id="lsr"><a href="#lsr" class="headerlink" title="[lsr]"></a>[lsr]</h3><p>使用方法：hadoop fs -lsr <args><br>说明：ls命令的递归版本。类似于Unix中的ls -R。</args></p>
<h3 id="mkdir"><a href="#mkdir" class="headerlink" title="[mkdir]"></a>[mkdir]</h3><p>使用方法：hadoop fs -mkdir <paths> 接受路径指定的uri作为参数，创建这些目录。其行为类似于Unix的mkdir -p，它会创建路径中的各级父目录。<br>Example: hadoop fs -mkdir /user/hadoop/dir1 /user/hadoop/dir2 hadoop fs -mkdir hdfs://host1:port1/user/hadoop/dir hdfs://host2:port2/user/hadoop/dir</paths></p>
<h3 id="mv"><a href="#mv" class="headerlink" title="[mv]"></a>[mv]</h3><p>使用方法： hadoop fs -mv URI [URI …] <dest><br>说明：将文件从源路径移动到目标路径。这个命令允许有多个源路径，此时目标路径必须是一个目录。不允许在不 同的文件系统间移动文件。<br>hadoop fs -mv /user/hadoop/file1 /user/hadoop/file2 hadoop fs -mv hdfs://host:port/file1 hdfs://host:port/file2 hdfs://host:port/file3 hdfs://host:port/dir1</dest></p>
<h3 id="put"><a href="#put" class="headerlink" title="[put]"></a>[put]</h3><p>使用方法：hadoop fs -put <localsrc> … <dst><br>说明：从本地文件系统中复制单个或多个源路径到目标文件系统。也支持从标准输入中读取输入写入目标文件系统。<br>Example: hadoop fs -put localfile /user/hadoop/hadoopfile hadoop fs -put localfile1 localfile2 /user/hadoop/hadoopdir hadoop fs -put - hdfs://host:port/hadoop/hadoopfile （从标准输入中读取输入。）</dst></localsrc></p>
<h3 id="rm"><a href="#rm" class="headerlink" title="[rm]"></a>[rm]</h3><p>使用方法： hadoop fs -rm URI [URI …]<br>删除指定的文件。只删除非空目录和文件。-r 递归删除。<br>Example: hadoop fs -rm hdfs://host:port/file /user/hadoop/emptydir </p>
<h3 id="setrep"><a href="#setrep" class="headerlink" title="[setrep]"></a>[setrep]</h3><p>使用方法： hadoop fs -setrep [-R] [-w] <numreplicas> <path><br>说明：改变一个文件的副本系数。-R选项用于递归改变目录下所有文件的副本系数。-w选项指定，改请求等待操作 执行结束。<br>hadoop fs -setrep -w 3 -R /user/hadoop/dir1</path></numreplicas></p>
<h3 id="stat"><a href="#stat" class="headerlink" title="[stat]"></a>[stat]</h3><p>使用方法： hadoop fs -tail [-f] URI<br>说明：返回指定路径的统计信息。<br>%F:文件<br>%b:文件大小<br>类型<br>%g:所属组<br>%o:block大小<br>%n:文件名<br>%r:复制因子数<br>%u:文件所有者<br>%Y,%y:修改日期<br>Example: hadoop fs -stat “%F %u:%g %b %y %n” /file</p>
<h3 id="tail"><a href="#tail" class="headerlink" title="[tail]"></a>[tail]</h3><p>使用方法： hadoop fs -tail [-f] URI 说明：将文件尾部1K字节的内容输出到stdout。支持-f选项，行为和Unix中一致。<br>Example: hadoop fs -tail pathname</p>
<h3 id="text"><a href="#text" class="headerlink" title="[text]"></a>[text]</h3><p>使用方法： hadoop fs -text <src> 说明：类似于cat。将源文件输出为文本格式。允许的格式是zip和TextRecordInputStream。</src></p>
<h3 id="touchz"><a href="#touchz" class="headerlink" title="[touchz]"></a>[touchz]</h3><p>使用方法：hadoop fs -touchz URI [URI …]<br>说明：创建一个0字节的空文件。<br>Example: Hadoop fs -touchz pathname</p>
<h3 id="truncate"><a href="#truncate" class="headerlink" title="[truncate]"></a>[truncate]</h3><p>使用方法：hadoop fs -truncate [-w] <length> <paths> 说明：文件截断，-w要求该命令等待恢复完成。<br>Example: hadoop fs -truncate 55 /user/hadoop/file1 /user/hadoop/file2 hadoop fs -truncate -w 127 hdfs://nn1.example.com/user/hadoop/file1</paths></length></p>
<h3 id="usage"><a href="#usage" class="headerlink" title="[usage]"></a>[usage]</h3><p>使用方法： hadoop fs -usage command<br>说明：返回命令的帮助信息。 </p>
<h3 id="find"><a href="#find" class="headerlink" title="[find]"></a>[find]</h3><p>使用方法：hadoop fs -find <path> … <expression> … 说明：查找满足表达式的文件和文件夹。没有配置path的话，默认的就是全部目录/；如果表达式没有配置，则默认 为-print。<br>-name pattern 不区分大小写，对大小写不敏感<br>-iname pattern 对大小写敏感。<br>-print 打印。 -print0 打印在一行。<br>Example: 。 Example:hadoop fs -find / -name test –print </expression></path></p>
<h3 id="getfacl"><a href="#getfacl" class="headerlink" title="[getfacl]"></a>[getfacl]</h3><p>使用方法：hadoop fs -getfacl [-R] <path><br>说明：获取文件的acl权限。-R指定递归查找<br>hadoop fs -getfacl -R /dir</path></p>
<h2 id="HDFS-dfsadmin"><a href="#HDFS-dfsadmin" class="headerlink" title="HDFS dfsadmin"></a>HDFS dfsadmin</h2><p>bin/hadoop dfsadmin命令支持一些和HDFS管理相关的操作。<br>bin/hadoop dfsadmin help 命令能列出所有当前支持的命令。<br>用法： hadoop dfsadmin [GENERIC_OPTIONS]<br>[-report]<br>[-safemode enter | leave | get | wait]<br>[-refreshNodes]<br>[-finalizeUpgrade]<br>[-upgradeProgress status | details | force]<br>[-metasave filename]<br>[-setQuota <quota> <dirname>…<dirname>]<br>[-clrQuota <dirname>…<dirname>]<br>[-help [cmd]]<br>说明：</dirname></dirname></dirname></dirname></quota></p>
<ul>
<li>-report: 报告文件系统的基本信息和统计信息。 </li>
<li>-safemode enter | leave | get | wait : 安全模式维护命令。安全模式是Namenode的一个状态，这种状态下，<br>Namenode </li>
</ul>
<ol>
<li>不接受对名字空间的更改(只读) </li>
<li>不复制或删除块<br>Namenode会在启动时自动进入安全模式，当配置的块最小百分比数满足最小的副本数条件时，会自动离开安全模式。安全模式可以手动进入，但是这样的话也必须手动关闭安全模式。</li>
</ol>
<ul>
<li>-refreshNodes :重新读取hosts和exclude文件，更新允许连到Namenode的或那些需要退出或入编的Datanode的集合。 </li>
<li>-finalizeUpgrade:终结HDFS的升级操作。Datanode删除前一个版本的工作目录，之后 Namenode也这样做。这个操作完结整个升级过程。 </li>
<li>-upgradeProgress status | details | force : 请求当前系统的升级状态，状态的细节，或者强制升级操作进行。</li>
<li>-metasave filename:保存Namenode的主要数据结构到hadoop.log.dir属性指定的目录下的<filename>文件。 对于下面的每一项，<filename>中都会一行内容与之对应<ol>
<li>Namenode收到的Datanode的心跳信号 </li>
<li>等待被复制的块 </li>
<li>正在被复制的块</li>
<li>等待被删除的块</li>
</ol>
</filename></filename></li>
<li>-setQuota <quota> <dirname>…<dirname>:为每个目录 <dirname>设定配额<quota>。目录配额是一个长整型整数，强制限定了目录树下的名字个数。 命令会在这个目录上工作良好，以下情况会报错： <ol>
<li>N不是一个正整数，或者 </li>
<li>用户不是管理员，或者 </li>
<li>这个目录不存在或是文件，或者</li>
<li>目录会马上超出新设定的配额。</li>
</ol>
</quota></dirname></dirname></dirname></quota></li>
<li>-clrQuota <dirname>…<dirname>:为每一个目录<dirname>清除配额设定。命令会在这个目录上工作良好，以下情况会报错： <ol>
<li>这个目录不存在或是文件，或者 </li>
<li>用户不是管理员。<br>如果目录原来没有配额不会报错。</li>
</ol>
</dirname></dirname></dirname></li>
</ul>
<p>Example:<br>hdfs –safemode enter|leave|get|wait<br>hdfs dfsadmin -getDatanodeInfo idh101:8010(<br>获取datanode信息，该命令用于检测datanode是否存活)<br>hdfs dfsadmin -shutdownDatanode idh101:8010 [upgrade]<br>hdfs dfsadmin -rollingUpgrade &lt;query|prepare|finalize&gt;<br>参照：<br>hadoop dfsadmin -setSpaceQuota 1g /user/seamon/<br>hadoop dfsadmin -clrSpaceQuota /user/seamon</p>
<p><a href="http://hadoop.apache.org/docs/r1.0.4/cn/commands_manual.html#dfsadmin" target="_blank" rel="noopener">http://hadoop.apache.org/docs/r1.0.4/cn/commands_manual.html#dfsadmin</a> <a href="http://hadoop.apache.org/docs/r2.7.3/hadoop-project-dist/hadoop-hdfs/HDFSCommands.html#dfsadmin" target="_blank" rel="noopener">http://hadoop.apache.org/docs/r2.7.3/hadoop-project-dist/hadoop-hdfs/HDFSCommands.html#dfsadmin</a><br><a href="http://hadoop.apache.org/docs/r2.7.3/hadoop-project-dist/hadoop-hdfs/HdfsRollingUpgrade.html" target="_blank" rel="noopener">http://hadoop.apache.org/docs/r2.7.3/hadoop-project-dist/hadoop-hdfs/HdfsRollingUpgrade.html</a></p>
<h2 id="HDFS-DistCp"><a href="#HDFS-DistCp" class="headerlink" title="HDFS DistCp"></a>HDFS DistCp</h2><p>DistCp（分布式拷贝）是用于大规模集群内部和集群之间拷贝的工具。 它使用 Map/Reduce实现文件分发，错误处理和恢复，以及报告生成。它把文件和目录的列表作为map任务的输入，每个任务会完成源列表中部分文件的拷贝。 由于使用了 Map/Reduce方法，这个工具在语义和执行上都会有特殊的地方。<br>使用方法： hadoop distcp hdfs://nn1:8020/foo/bar \ hdfs://nn2:8020/bar/foo<br>命令行中可以指定多个源目录：<br>hadoop distcp hdfs://nn1:8020/foo/a \<br>hdfs://nn1:8020/foo/b \<br>hdfs://nn2:8020/bar/foo<br>或者使用-f选项，从文件里获得多个源：<br>hadoop distcp -f hdfs://nn1:8020/srclist \<br>hdfs://nn2:8020/bar/foo<br>其中srclist 的内容是<br>hdfs://nn1:8020/foo/a<br>hdfs://nn1:8020/foo/b<br>参照：<a href="http://hadoop.apache.org/docs/r1.0.4/cn/distcp.html" target="_blank" rel="noopener">http://hadoop.apache.org/docs/r1.0.4/cn/distcp.html</a></p>
<h2 id="HDFS-getConf"><a href="#HDFS-getConf" class="headerlink" title="HDFS getConf"></a>HDFS getConf</h2><p>说明：用于获取hdfs配置信息。<br>Example:<br>hdfs getconf -namenodes<br>hdfs getconf -secondaryNameNodes<br>hdfs getconf -backupNodes<br>hdfs getconf -includeFile<br>hdfs getconf -excludeFile<br>hdfs getconf -nnRpcAddresses<br>hdfs getconf -confKey dfs.namenode.name.dir<br>hdfs getconf -confKey dfs.datanode.data.dir<br>hdfs getconf -confKey dfs.replication </p>
<p>参照：<a href="http://hadoop.apache.org/docs/r2.7.3/hadoop-project-dist/hadoop-hdfs/HDFSCommands.html#getconf" target="_blank" rel="noopener">http://hadoop.apache.org/docs/r2.7.3/hadoop-project-dist/hadoop-hdfs/HDFSCommands.html#getconf</a></p>
<h2 id="HDFS-oev"><a href="#HDFS-oev" class="headerlink" title="HDFS oev"></a>HDFS oev</h2><p>用法： hdfs oev [OPTIONS] -i INPUT_FILE -o OUTPUT_FILE<br>说明：命令hdfs oev用于查看edits文件。<br>-i,–inputFile <arg> 输入edits文件，如果是xml后缀，表示XML格式，其他表示二进制。 -o,–outputFile <arg> 输出文件，如果存在，则会覆盖。<br>可选参数：<br>-p,–processor <arg> 指定转换类型: binary (二进制格式), xml (默认，XML格式),stats (打印edits文件的静态统计信息)<br>-f,–fix-txids 重置输入edits文件中的transaction IDs<br>-r,–recover 使用recovery模式，跳过eidts中的错误记录。<br>-v,–verbose 打印处理时候的输出。<br>Example: hdfs oev -i /data1/hadoop/hdfs/name/current/edits_0000000000019382469-0000000000019383915 -o /home/hadoop/edits.xml<br>未指定-p选项，默认转换成xml格式，查看edits.xml文件。输出的xml文件中记录了文件路径（PATH），修改时间 （MTIME）、添加时间（ATIME）、客户端名称（CLIENT_NAME）、客户端地址（CLIENT_MACHINE）、权限 （PERMISSION_STATUS）等非常有用的信息。<br>当edits文件破损进而导致HDFS文件系统出现问题时，可以通过将原有的binary文件转换为xml文件，并手动编辑xml文件然后转回binary文件来实现。 </arg></arg></arg></p>
<p>参照： <a href="http://lxw1234.com/archives/2015/08/442.htm" target="_blank" rel="noopener">http://lxw1234.com/archives/2015/08/442.htm</a></p>
<h2 id="HDFS-oiv"><a href="#HDFS-oiv" class="headerlink" title="HDFS oiv"></a>HDFS oiv</h2><p>用法： hdfs oiv [OPTIONS] -i INPUT_FILE<br>说明：命令hdfs oiv用于将fsimage文件转换成其他格式的，如文本文件、XML文件。 -i,–inputFile <arg> 输入FSImage文件。<br>-o,–outputFile <arg> 输出转换后的文件，如果存在，则会覆盖。<br>可选参数：<br>-p,–processor <arg> 将FSImage文件转换成哪种格式：(Ls|XML|FileDistribution).默认为Ls.<br>-h,–help 显示帮助信息<br>Example:<br>hdfs oiv -i /data1/hadoop/dfs/name/current/fsimage_0000000000019372521 -o /home/hadoop/fsimage.txt<br>由于未指定-p选项，默认为Ls，出来的结果和执行hadoop fs –ls –R一样。<br>hdfs oiv -i /data1/hadoop/dfs/name/current/fsimage_0000000000019372521 -o /home/hadoop/fsimage.xml-p XML<br>指定-p XML，将fsimage文件转换成XML格式，查看fsimage.xml XML文件中包含了fsimage中的所有信息，比如inodeid、type、name、修改时间、权限、大小等等。</arg></arg></arg></p>
<p>参照：<a href="http://lxw1234.com/archives/2015/08/440.htm" target="_blank" rel="noopener">http://lxw1234.com/archives/2015/08/440.htm</a></p>
<h2 id="HDFS-fsck"><a href="#HDFS-fsck" class="headerlink" title="HDFS fsck"></a>HDFS fsck</h2><p>用法： hdfs fsck <path> [-list-corruptfileblocks |[-move | -delete | -openforwrite] [-files [-blocks [-locations | racks]]] [-includeSnapshots] [-storagepolicies] [-blockId <blk_id>] 说明：检查HDFS上文件和目录的健康状态、获取文件的block信息和位置信息等。 -list-corruptfileblocks:查看文件中损坏的块<br>-move:将损坏的文件移动至/lost+found目录<br>-delete:删除损坏的文件 -files:检查并列出所有文件状态 -openforwrite:检查并打印正在被打开执行写操作的文件 -blocks:打印文件的Block报告（需要和-files一起使用） -locations:打印文件块的位置信息（需要和-files -blocks一起使用。） -racks:打印文件块位置所在的机架信息<br>Example: hdfs fsck /hivedata/warehouse/liuxiaowen.db/lxw_product_names/ -list-corruptfileblocks<br>hdfs fsck /hivedata/warehouse/liuxiaowen.db/lxw_product_names/part-00168 –move hdfs fsck /hivedata/warehouse/liuxiaowen.db/lxw_product_names/part-00168 –delete<br>hdfs fsck /hivedata/warehouse/liuxiaowen.db/lxw_product_names/ -files </blk_id></path></p>
<p>参照：<a href="http://lxw1234.com/archives/2015/08/452.htm" target="_blank" rel="noopener">http://lxw1234.com/archives/2015/08/452.htm</a></p>
<h2 id="HDFS-balancer"><a href="#HDFS-balancer" class="headerlink" title="HDFS balancer"></a>HDFS balancer</h2><ul>
<li>添加新的DataNode节点。</li>
<li>人为干预，修改block副本数。</li>
<li>各个机器磁盘大小不一致。</li>
<li>长时间运行大量的delete操作等。</li>
</ul>
<p>Hadoop提供了Balancer工具来改善磁盘不均衡的问题。</p>
<p>用法： hdfs balancer [-threshold <threshold>] [-policy <policy>] [-exclude [-f <hosts-file> | <comma-separated list of hosts>]] [-include [-f <hosts-file> | <comma-separated list of hosts>]] [-idleiterations <idleiterations>]<br>说明：用于平衡hadoop集群中各datanode中的文件块分布，以避免出现部分datanode磁盘占用率高的问题。<br>-threshold <threshold>:表示的平衡的阀值，取值范围在0%到100%之间。每个Datanode中空间使用率与HDFS集群总 的空间使用率的差距百分比。<br>-policy <policy>：平衡策略，默认DataNode。应用于重新平衡HDFS存储的策略。默认DataNode策略平衡了DataNode级别的存储。这类似于之前发行版的平衡策略。BlockPool策略平衡了块池级别和DataNode级别的存储。 BlockPool策略仅适用于Federated HDFS服务。<br>-exclude/include:参数-exclude和-include是用来选择balancer时，可以指定哪几个DataNode之间重分布，也可以从HDFS 集群中排除哪几个节点不需要重分布<br>-idleiterations <iterations>:迭代检测的次数。<br>Example: hdfs balancer –threshold 10</iterations></policy></threshold></idleiterations></comma-separated></hosts-file></comma-separated></hosts-file></policy></threshold></p>
<h2 id="HDFS-快照"><a href="#HDFS-快照" class="headerlink" title="HDFS 快照"></a>HDFS 快照</h2><p>HDFS快照是一个只读的基于时间点文件系统拷贝。快照可以是整个文件系统的也可以是一部分。常用来作为数据备份，防止用户错误和容灾。<br>在datanode上面的blocks不会复制，做Snapshot的文件是纪录了block的列表和文件的大小，但是没有数据的复制Snapshot并不会影响HDFS的正常操作：修改会按照时间的反序记录，这样可以直接读取到最新的数据。快照数据是当前数据减去修改的部分计算出来的。<br>快照会存储在snapshottable的目录下。snapshottable下存储的snapshots最多为65535个。没有限制snapshottable目录 的数量。管理员可以设置任何的目录成为snapshottable。如果snapshottable里面存着快照，那么文件夹不能删除或者 改名。<br>快照常用操作<br>hdfs dfsadmin -allowSnapshot <path>：快照目录建立。如果这个操作成果，那么目录会变成snapshottable hdfs dfsadmin -disallowSnapshot <path>：文件夹里面的所有快照在失效快照前必须被删除，如果没有该目录会被建立。<br>hdfs dfsadmin -createSnapshot <path> [<snapshotname>]：snapshottable目录创建一个快照。这个操作需要 snapshottable目录的权限。<br>hdfs dfsadmin -deleteSnapshot <path> <snapshotname>：从一个snapshottable目录删除的快照。这个操作需要 snapshottable目录的权限。<br>hdfs dfsadmin -renameSnapshot <path> <oldname> <newname>：重命名快照。这个命令也需要snapshottable目录的权限。<br>hdfs lsSnapshottableDir：获取当前用户的所有snapshottable。 hdfs snapshotDiff <path> <fromsnapshot> <tosnapshot>：得到两个快照之间的不同。需要两个目录的权限。<br>参照：<a href="http://blog.csdn.net/linlinv3/article/details/44564313" target="_blank" rel="noopener">http://blog.csdn.net/linlinv3/article/details/44564313</a></tosnapshot></fromsnapshot></path></newname></oldname></path></snapshotname></path></snapshotname></path></path></path></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul>
<li>HDFS架构及其实现原理。<ul>
<li>中心化设计，主从结构。NN+DN+SD+Client。</li>
<li>NN存储元数据信息，内存+持久化数据(fsimage+editlogs)</li>
<li>SD作为助手，定期合并editlogs到fsimage。</li>
</ul>
</li>
<li>HDFS写入/读取数据流程。<ul>
<li>建立流水线</li>
<li>写入数据</li>
<li>关闭流水线</li>
</ul>
</li>
<li>HDFS shell命令。</li>
</ul>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script></div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">zheroic</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://zheroic.github.io/2019/09/27/hadoop-2/">https://zheroic.github.io/2019/09/27/hadoop-2/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://zheroic.github.io">zh小企鹅</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/hadoop/">hadoop    </a></div><div class="post_share"><div class="social-share" data-image="https://pic.superbed.cn/item/5d8d5e78451253d17830baa7.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script></div></div><nav class="pagination_post" id="pagination"><div class="prev-post pull-left"><a href="/2019/10/08/data-science-1/"><img class="prev_cover lozad" data-src="https://pic.superbed.cn/item/5d9d62b5451253d17884eb5d.png" onerror="onerror=null;src='/img/404.jpg'"><div class="label">上一篇</div><div class="prev_info"><span>数据科学导论-1：探索性数据分析和数据预处理</span></div></a></div><div class="next-post pull-right"><a href="/2019/09/27/hadoop-1/"><img class="next_cover lozad" data-src="https://pic.superbed.cn/item/5d8d569d451253d1782f0d92.png" onerror="onerror=null;src='/img/404.jpg'"><div class="label">下一篇</div><div class="next_info"><span>hadoop离线计算-1:初识Hadoop</span></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2019/09/27/hadoop-1/" title="hadoop离线计算-1:初识Hadoop"><img class="relatedPosts_cover lozad" data-src="https://pic.superbed.cn/item/5d8d569d451253d1782f0d92.png"><div class="relatedPosts_title">hadoop离线计算-1:初识Hadoop</div></a></div><div class="relatedPosts_item"><a href="/2019/10/14/hadoop-3/" title="hadoop-3"><img class="relatedPosts_cover lozad" data-src="https://pic.superbed.cn/item/5da48963451253d1788afc67.png"><div class="relatedPosts_title">hadoop-3</div></a></div></div><div class="clear_both"></div></div><hr><div id="post-comment"><div class="comment_headling"><i class="fa fa-comments fa-fw" aria-hidden="true"></i><span> 评论</span></div><div id="gitalk-container"></div><script>var gitalk = new Gitalk({
  clientID: '3875e95f58ea59855e05',
  clientSecret: '335bf09bc36a5dae2109909b8b305e96c7966880',
  repo: 'zheroic.github.io',
  owner: 'zheroic',
  admin: 'zheroic',
  id: md5(decodeURI(location.pathname)),
  language: 'zh-CN'
})
gitalk.render('gitalk-container')</script></div></div></div><footer><div id="footer"><div class="copyright">&copy;2019 By zheroic</div><div class="framework-info"><span>驱动 </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly"><span>Butterfly</span></a></div><div class="footer_custom_text">Hi, welcome to my <a href="https://zheroic.github.io/">blog</a>!</div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><section class="rightside" id="rightside"><a id="to_comment" href="#post-comment"><i class="scroll_to_comment fa fa-comments"></i></a><i class="fa fa-book" id="readmode" title="阅读模式"> </i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换">繁</a><i class="nightshift fa fa-moon-o" id="nightshift" title="夜间模式"></i></section><div class=" " id="post_bottom"><div id="post_bottom_items"><a id="mobile_to_comment" href="#post-comment"><i class="mobile_scroll_to_comment fa fa-comments"></i></a><i class="fa fa-list" id="mobile_toc"></i><div id="toc_mobile"><div class="toc_mobile_headline">目录</div><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#Hadoop分布式文件存储系统"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text">Hadoop分布式文件存储系统</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#hadoop简介"><span class="toc_mobile_items-number">1.1.</span> <span class="toc_mobile_items-text">hadoop简介</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#官方定义："><span class="toc_mobile_items-number">1.1.1.</span> <span class="toc_mobile_items-text">官方定义：</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#基本原理："><span class="toc_mobile_items-number">1.1.2.</span> <span class="toc_mobile_items-text">基本原理：</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Hadoop实现原理"><span class="toc_mobile_items-number">1.2.</span> <span class="toc_mobile_items-text">Hadoop实现原理</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#基本原理：-1"><span class="toc_mobile_items-number">1.2.1.</span> <span class="toc_mobile_items-text">基本原理：</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#优点："><span class="toc_mobile_items-number">1.2.2.</span> <span class="toc_mobile_items-text">优点：</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#缺点："><span class="toc_mobile_items-number">1.2.3.</span> <span class="toc_mobile_items-text">缺点：</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#HDFS实现原理-namenode和datanode"><span class="toc_mobile_items-number">1.3.</span> <span class="toc_mobile_items-text">HDFS实现原理-namenode和datanode</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#HDFS实现原理"><span class="toc_mobile_items-number">1.4.</span> <span class="toc_mobile_items-text">HDFS实现原理</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#数据块"><span class="toc_mobile_items-number">1.4.1.</span> <span class="toc_mobile_items-text">数据块:</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#优点：-1"><span class="toc_mobile_items-number">1.4.2.</span> <span class="toc_mobile_items-text">优点：</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#NameNode"><span class="toc_mobile_items-number">1.4.3.</span> <span class="toc_mobile_items-text">NameNode</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#功能"><span class="toc_mobile_items-number">1.4.3.1.</span> <span class="toc_mobile_items-text">功能</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#Secondary-NameNode"><span class="toc_mobile_items-number">1.4.4.</span> <span class="toc_mobile_items-text">Secondary NameNode</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#功能-1"><span class="toc_mobile_items-number">1.4.4.1.</span> <span class="toc_mobile_items-text">功能</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#DataNode"><span class="toc_mobile_items-number">1.4.5.</span> <span class="toc_mobile_items-text">DataNode</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#功能-2"><span class="toc_mobile_items-number">1.4.5.1.</span> <span class="toc_mobile_items-text">功能</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#复制因子-block"><span class="toc_mobile_items-number">1.4.6.</span> <span class="toc_mobile_items-text">复制因子(block)</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#机架感知"><span class="toc_mobile_items-number">1.4.7.</span> <span class="toc_mobile_items-text">机架感知</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#HDFS读写流程-写数据"><span class="toc_mobile_items-number">1.5.</span> <span class="toc_mobile_items-text">HDFS读写流程-写数据</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#HDFS读写流程-写数据之建立流水线（pipline）"><span class="toc_mobile_items-number">1.6.</span> <span class="toc_mobile_items-text">HDFS读写流程-写数据之建立流水线（pipline）</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#HDFS读写流程-写数据之数据复制（data-Streaming"><span class="toc_mobile_items-number">1.7.</span> <span class="toc_mobile_items-text">HDFS读写流程-写数据之数据复制（data Streaming)</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#HDFS读写流程-写数据之关闭流水线"><span class="toc_mobile_items-number">1.8.</span> <span class="toc_mobile_items-text">HDFS读写流程-写数据之关闭流水线</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#HDFS读写流程-多个Block同时写入"><span class="toc_mobile_items-number">1.9.</span> <span class="toc_mobile_items-text">HDFS读写流程-多个Block同时写入</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#HDFS读写流程-文件读取"><span class="toc_mobile_items-number">1.10.</span> <span class="toc_mobile_items-text">HDFS读写流程-文件读取</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#HDFS-filesystem-shell"><span class="toc_mobile_items-number">1.11.</span> <span class="toc_mobile_items-text">HDFS filesystem shell</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#cat"><span class="toc_mobile_items-number">1.11.1.</span> <span class="toc_mobile_items-text">[cat]</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#appendToFile"><span class="toc_mobile_items-number">1.11.2.</span> <span class="toc_mobile_items-text">[appendToFile]</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#chgrp"><span class="toc_mobile_items-number">1.11.3.</span> <span class="toc_mobile_items-text">[chgrp]</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#chmod"><span class="toc_mobile_items-number">1.11.4.</span> <span class="toc_mobile_items-text">[chmod]</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#chown"><span class="toc_mobile_items-number">1.11.5.</span> <span class="toc_mobile_items-text">[chown]</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#copyFromLocal"><span class="toc_mobile_items-number">1.11.6.</span> <span class="toc_mobile_items-text">[copyFromLocal]</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#copyToLocal"><span class="toc_mobile_items-number">1.11.7.</span> <span class="toc_mobile_items-text">[copyToLocal]</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#count"><span class="toc_mobile_items-number">1.11.8.</span> <span class="toc_mobile_items-text">[count]</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#cp"><span class="toc_mobile_items-number">1.11.9.</span> <span class="toc_mobile_items-text">[cp]</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#df"><span class="toc_mobile_items-number">1.11.10.</span> <span class="toc_mobile_items-text">[df]</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#expunge"><span class="toc_mobile_items-number">1.11.11.</span> <span class="toc_mobile_items-text">[expunge]</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#get"><span class="toc_mobile_items-number">1.11.12.</span> <span class="toc_mobile_items-text">[get]</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#getmerge"><span class="toc_mobile_items-number">1.11.13.</span> <span class="toc_mobile_items-text">[getmerge]</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#ls"><span class="toc_mobile_items-number">1.11.14.</span> <span class="toc_mobile_items-text">[ls]</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#lsr"><span class="toc_mobile_items-number">1.11.15.</span> <span class="toc_mobile_items-text">[lsr]</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#mkdir"><span class="toc_mobile_items-number">1.11.16.</span> <span class="toc_mobile_items-text">[mkdir]</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#mv"><span class="toc_mobile_items-number">1.11.17.</span> <span class="toc_mobile_items-text">[mv]</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#put"><span class="toc_mobile_items-number">1.11.18.</span> <span class="toc_mobile_items-text">[put]</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#rm"><span class="toc_mobile_items-number">1.11.19.</span> <span class="toc_mobile_items-text">[rm]</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#setrep"><span class="toc_mobile_items-number">1.11.20.</span> <span class="toc_mobile_items-text">[setrep]</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#stat"><span class="toc_mobile_items-number">1.11.21.</span> <span class="toc_mobile_items-text">[stat]</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#tail"><span class="toc_mobile_items-number">1.11.22.</span> <span class="toc_mobile_items-text">[tail]</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#text"><span class="toc_mobile_items-number">1.11.23.</span> <span class="toc_mobile_items-text">[text]</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#touchz"><span class="toc_mobile_items-number">1.11.24.</span> <span class="toc_mobile_items-text">[touchz]</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#truncate"><span class="toc_mobile_items-number">1.11.25.</span> <span class="toc_mobile_items-text">[truncate]</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#usage"><span class="toc_mobile_items-number">1.11.26.</span> <span class="toc_mobile_items-text">[usage]</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#find"><span class="toc_mobile_items-number">1.11.27.</span> <span class="toc_mobile_items-text">[find]</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#getfacl"><span class="toc_mobile_items-number">1.11.28.</span> <span class="toc_mobile_items-text">[getfacl]</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#HDFS-dfsadmin"><span class="toc_mobile_items-number">1.12.</span> <span class="toc_mobile_items-text">HDFS dfsadmin</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#HDFS-DistCp"><span class="toc_mobile_items-number">1.13.</span> <span class="toc_mobile_items-text">HDFS DistCp</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#HDFS-getConf"><span class="toc_mobile_items-number">1.14.</span> <span class="toc_mobile_items-text">HDFS getConf</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#HDFS-oev"><span class="toc_mobile_items-number">1.15.</span> <span class="toc_mobile_items-text">HDFS oev</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#HDFS-oiv"><span class="toc_mobile_items-number">1.16.</span> <span class="toc_mobile_items-text">HDFS oiv</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#HDFS-fsck"><span class="toc_mobile_items-number">1.17.</span> <span class="toc_mobile_items-text">HDFS fsck</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#HDFS-balancer"><span class="toc_mobile_items-number">1.18.</span> <span class="toc_mobile_items-text">HDFS balancer</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#HDFS-快照"><span class="toc_mobile_items-number">1.19.</span> <span class="toc_mobile_items-text">HDFS 快照</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#总结"><span class="toc_mobile_items-number">1.20.</span> <span class="toc_mobile_items-text">总结</span></a></li></ol></li></ol></div></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script async src="/js/search/local-search.js"></script><script src="/js/nightshift.js"></script><script src="/js/tw_cn.js"></script><script>translateInitilization()

</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@1.2.2/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script><script>const observer = lozad(); // lazy loads elements with default selector as '.lozad'
observer.observe();</script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>