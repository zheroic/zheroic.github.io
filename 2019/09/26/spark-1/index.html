<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>Spark内存计算-1:初识Spark | zh小企鹅</title><meta name="description" content="Spark内存计算-1:初识Spark"><meta name="keywords" content="spark"><meta name="author" content="zheroic"><meta name="copyright" content="zheroic"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon1.png"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="canonical" href="https://zheroic.github.io/2019/09/26/spark-1/"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:title" content="Spark内存计算-1:初识Spark"><meta name="twitter:description" content="Spark内存计算-1:初识Spark"><meta name="twitter:image" content="https://pic.superbed.cn/item/5d8c9264451253d178e2de72.png"><meta property="og:type" content="article"><meta property="og:title" content="Spark内存计算-1:初识Spark"><meta property="og:url" content="https://zheroic.github.io/2019/09/26/spark-1/"><meta property="og:site_name" content="zh小企鹅"><meta property="og:description" content="Spark内存计算-1:初识Spark"><meta property="og:image" content="https://pic.superbed.cn/item/5d8c9264451253d178e2de72.png"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="prev" title="hadoop离线计算-1:初识Hadoop" href="https://zheroic.github.io/2019/09/27/hadoop-1/"><link rel="next" title="软件需求分析设计-2" href="https://zheroic.github.io/2019/09/25/software-requirement-2/"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css"><script src="https://cdn.jsdelivr.net/gh/upupming/gitalk@36368e5dffd049e956cdbbd751ff96c28d8255cf/dist/gitalk.min.js"></script><script src="https://cdn.jsdelivr.net/npm/blueimp-md5@2.10.0/js/md5.min.js"></script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  highlight_copy: 'true',
  highlight_lang: 'true',
  highlight_shrink: 'false',
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    title: '添加书签',
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天'

  
}</script><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head><body><div id="web_bg"></div><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#初识Spark"><span class="toc-text">初识Spark</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#大数据技术框架"><span class="toc-text">大数据技术框架</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Spark背景-HDFS"><span class="toc-text">Spark背景-HDFS</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#官方定义："><span class="toc-text">官方定义：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#基本原理："><span class="toc-text">基本原理：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#优点："><span class="toc-text">优点：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#缺点："><span class="toc-text">缺点：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Spark背景-资源调度"><span class="toc-text">Spark背景-资源调度</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Spark背景-Mapreduce"><span class="toc-text">Spark背景-Mapreduce</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#为什么需要？"><span class="toc-text">为什么需要？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#大规模数据处理时，MapReduce在三个层次上的基本构思："><span class="toc-text">大规模数据处理时，MapReduce在三个层次上的基本构思：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#结论："><span class="toc-text">结论：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Map"><span class="toc-text">Map</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Reduce"><span class="toc-text">Reduce</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#局限性"><span class="toc-text">局限性</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Spark背景：计算框架多样化"><span class="toc-text">Spark背景：计算框架多样化</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#现有的计算框架"><span class="toc-text">现有的计算框架</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Spark背景：什么是Spark"><span class="toc-text">Spark背景：什么是Spark</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark："><span class="toc-text">Spark：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Spark生态系统："><span class="toc-text">Spark生态系统：</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark基本概念"><span class="toc-text">Spark基本概念</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Spark-Core-Spark的核心功能实现"><span class="toc-text">Spark Core : Spark的核心功能实现</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Spark-SQL："><span class="toc-text">Spark SQL：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Spark-Streaming："><span class="toc-text">Spark Streaming：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#GraphX："><span class="toc-text">GraphX：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#MLlib："><span class="toc-text">MLlib：</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#计算类型及应用场景"><span class="toc-text">计算类型及应用场景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Spark特性-DAG"><span class="toc-text">Spark特性-DAG</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Spark核心概念-RDD"><span class="toc-text">Spark核心概念-RDD</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#RDD：弹性分布式数据集-Resilient-Distributed-Datasets"><span class="toc-text">RDD：弹性分布式数据集(Resilient Distributed Datasets)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Spark核心概念-RDD基本操作"><span class="toc-text">Spark核心概念-RDD基本操作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Transformation："><span class="toc-text">Transformation：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Action："><span class="toc-text">Action：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#WordCount-example"><span class="toc-text">WordCount example</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Spark核心概念-RDD的缓存位置"><span class="toc-text">Spark核心概念-RDD的缓存位置</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Spark基本架构"><span class="toc-text">Spark基本架构</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Cluster-Manager："><span class="toc-text">Cluster Manager：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Driver-Programe："><span class="toc-text">Driver Programe：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Worker-Node："><span class="toc-text">Worker Node：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Executor"><span class="toc-text">Executor:</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Spark运行模式"><span class="toc-text">Spark运行模式</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Local模式："><span class="toc-text">Local模式：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Standalone模式："><span class="toc-text">Standalone模式：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark-On-Yarn-Mesos模式："><span class="toc-text">Spark On Yarn/Mesos模式：</span></a></li></ol></li></ol></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://pic.superbed.cn/item/5d8c9264451253d178e2de72.png)"><div id="page-header"><span class="pull-left"> <a class="blog_title" id="site-name" href="/">zh小企鹅</a></span><div class="open toggle-menu pull-right"><div class="menu-icon-first"></div><div class="menu-icon-second"></div><div class="menu-icon-third"></div></div><div class="menu_mask"></div><span class="pull-right menus"><div class="mobile_author_icon"><img class="lozad avatar_img" src="https://pic.superbed.cn/item/5d7a3f76451253d1788f04d2.jpg" onerror="onerror=null;src='/img/friend_404.gif'"></div><div class="mobile_post_data"><div class="mobile_data_item text-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">10</div></a></div></div><div class="mobile_data_item text-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">6</div></a></div></div><div class="mobile_data_item text-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">3</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/contact/"><i class="fa-fw fa fa-comments"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于我</span></a></div><script>document.body.addEventListener('touchstart', function(){ });</script></div></span><span class="pull-right"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i><span> 搜索</span></a></span></div><div id="post-info"><div id="post-title"><div class="posttitle">Spark内存计算-1:初识Spark</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 发表于 2019-09-26<span class="post-meta__separator">|</span><i class="fa fa-history" aria-hidden="true"></i> 更新于 2019-09-27</time><span class="post-meta__separator mobile_hidden">|</span><span class="mobile_hidden"><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/技术/">技术</a></span><div class="post-meta-wordcount"><span>字数总计: </span><span class="word-count">3.9k</span><span class="post-meta__separator">|</span><span>阅读时长: 15 分钟</span><span class="post-meta__separator">|</span><span>阅读量: </span><span id="busuanzi_value_page_pv"></span></div></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><h1 id="初识Spark"><a href="#初识Spark" class="headerlink" title="初识Spark"></a>初识Spark</h1><h2 id="大数据技术框架"><a href="#大数据技术框架" class="headerlink" title="大数据技术框架"></a>大数据技术框架</h2><p><img alt="大数据技术框架-1" data-src="https://pic.superbed.cn/item/5d8c7975451253d178dc6217.png" class="lozad"><br><img alt="大数据技术框架-2" data-src="https://pic.superbed.cn/item/5d8c7b5f451253d178dcdca7.png" class="lozad"><br><img alt="大数据技术框架-3" data-src="https://pic.superbed.cn/item/5d8c7bc2451253d178dcf470.png" class="lozad"></p>
<h2 id="Spark背景-HDFS"><a href="#Spark背景-HDFS" class="headerlink" title="Spark背景-HDFS"></a>Spark背景-HDFS</h2><h3 id="官方定义："><a href="#官方定义：" class="headerlink" title="官方定义："></a>官方定义：</h3><p>分布式存储系统HDFS（Hadoop Distributed File System）。<br>其实就是一个文件系统，类似于linux的文件系统。有目录，目录下可以存储文件。但它又是一个分布式的文件系统。</p>
<h3 id="基本原理："><a href="#基本原理：" class="headerlink" title="基本原理："></a>基本原理：</h3><ul>
<li>将文件切分成等大的数据块。分别存储到多台机器上。</li>
<li>每个数据块存在多个备份。</li>
<li>将数据切分、容错、负载均衡等功能透明化。</li>
<li>可将HDFS看成是一个巨大、具有容错性的磁盘。<br><img alt="HDFS架构" data-src="https://pic.superbed.cn/item/5d8c8f8d451253d178e227b1.png" class="lozad"></li>
</ul>
<h3 id="优点："><a href="#优点：" class="headerlink" title="优点："></a>优点：</h3><ul>
<li>处理超大文件</li>
<li>流式的数据访问</li>
<li>运行于廉价的商业机器集群上</li>
</ul>
<h3 id="缺点："><a href="#缺点：" class="headerlink" title="缺点："></a>缺点：</h3><ul>
<li>不适合存储大量小文件</li>
<li>不适合低延迟数据访问</li>
<li>不支持多用户写入及任意修改文件</li>
</ul>
<h2 id="Spark背景-资源调度"><a href="#Spark背景-资源调度" class="headerlink" title="Spark背景-资源调度"></a>Spark背景-资源调度</h2><ul>
<li>Hadoop2.0提出的资源管理层</li>
<li>用于集群资源管理和应用调度</li>
<li>使得多种计算框架可以运行在一个集群中</li>
<li>mapreduce仅仅是Yarn的一种应用模式</li>
</ul>
<h2 id="Spark背景-Mapreduce"><a href="#Spark背景-Mapreduce" class="headerlink" title="Spark背景-Mapreduce"></a>Spark背景-Mapreduce</h2><p>一个大数据若可以分为具有相同计算过程的数据块，并且这些数据块之间<strong>不存在数据依赖</strong>关系，则提高处理速度的最好方法就是<strong>并行计算</strong>。<br>Master：负责划分和分配任务<br>Worker：负责数据块计算</p>
<h3 id="为什么需要？"><a href="#为什么需要？" class="headerlink" title="为什么需要？"></a>为什么需要？</h3><ul>
<li>并行计算技术和并行程序设计的复杂性</li>
<li>海量数据处理需要有效的并行处理技术</li>
<li>MapReduce是面向海量数据比较成功的技术</li>
</ul>
<h3 id="大规模数据处理时，MapReduce在三个层次上的基本构思："><a href="#大规模数据处理时，MapReduce在三个层次上的基本构思：" class="headerlink" title="大规模数据处理时，MapReduce在三个层次上的基本构思："></a>大规模数据处理时，MapReduce在三个层次上的基本构思：</h3><p>1.如何对付大数据处理：分而治之<br>2.上升到抽象模型：Mapper与Reducer<br>3.上升到构架：统一构架，为程序员隐藏系统层细节</p>
<h3 id="结论："><a href="#结论：" class="headerlink" title="结论："></a>结论：</h3><p><strong>不可分拆的计算任务或者相互间有依赖关系的数据无法进行并行计算！</strong><br><img alt="MapReduce" data-src="https://pic.superbed.cn/item/5d8c974b451253d178e41743.png" class="lozad"></p>
<h3 id="Map"><a href="#Map" class="headerlink" title="Map"></a>Map</h3><pre class=" language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">class</span> <span class="token class-name">Map</span> <span class="token keyword">extends</span> <span class="token class-name">Mapper</span><span class="token operator">&lt;</span>Object<span class="token punctuation">,</span>Text<span class="token punctuation">,</span>Text<span class="token punctuation">,</span>IntWritable<span class="token operator">></span><span class="token punctuation">{</span>
    <span class="token comment" spellcheck="true">//one表示单词只出现一次</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> IntWriteable one <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">IntWritable</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment" spellcheck="true">//word存储切下的单词</span>
    <span class="token keyword">private</span> Text word <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Text</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">map</span><span class="token punctuation">(</span>Object key<span class="token punctuation">,</span>Text value<span class="token punctuation">,</span>Context context<span class="token punctuation">)</span> <span class="token keyword">throw</span> IOException<span class="token punctuation">,</span>InterruptedException<span class="token punctuation">{</span>
        <span class="token comment" spellcheck="true">//对输入的行切词</span>
        StringTokenizer st <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">StringTokenizer</span><span class="token punctuation">(</span>value<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">while</span><span class="token punctuation">(</span>st<span class="token punctuation">.</span><span class="token function">hasMoreTokens</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            word<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>st<span class="token punctuation">.</span><span class="token function">nextToken</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//切下的单词存入word</span>
            context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>word<span class="token punctuation">,</span>one<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span></code></pre>
<h3 id="Reduce"><a href="#Reduce" class="headerlink" title="Reduce"></a>Reduce</h3><pre class=" language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">class</span> <span class="token class-name">Reduce</span> <span class="token keyword">extends</span> <span class="token class-name">Reducer</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span>IntWritable<span class="token punctuation">,</span>Text<span class="token punctuation">,</span>IntWritable<span class="token operator">></span><span class="token punctuation">{</span>
    <span class="token comment" spellcheck="true">//result记录单词的频数</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> IntWritable result <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">IntWritable</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">reduce</span><span class="token punctuation">(</span>Text<span class="token operator">/</span>key<span class="token punctuation">,</span>Iterable<span class="token operator">&lt;</span>IntWritable<span class="token operator">></span> value<span class="token punctuation">,</span>Context context<span class="token punctuation">)</span> <span class="token keyword">throw</span> IOException<span class="token punctuation">,</span>InterruptedException<span class="token punctuation">{</span>
        <span class="token keyword">int</span> sum <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
        <span class="token comment" spellcheck="true">//对获取的&lt;key,value-list>计算value的和</span>
        <span class="token keyword">for</span><span class="token punctuation">(</span>IntWritable val<span class="token operator">:</span>values<span class="token punctuation">)</span><span class="token punctuation">{</span>
            sum <span class="token operator">+=</span> val<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
        <span class="token comment" spellcheck="true">//将频数设置到result</span>
        result<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>sum<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment" spellcheck="true">//收集结果</span>
        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span>result<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span></code></pre>
<h3 id="局限性"><a href="#局限性" class="headerlink" title="局限性"></a>局限性</h3><ul>
<li>仅支持Map和Reduce操作（编程简单但是代码量大）</li>
<li>处理效率低<ul>
<li>Map中间结果写入磁盘。多个MapReduce之间通过HDFS交换数据</li>
<li>Map和Reduce端均需要排序</li>
<li>无法充分利用内存</li>
<li>任务调度和启用的开销较大</li>
</ul>
</li>
<li>不适合迭代计算（机器学习，图计算等）、交互式处理（数据挖掘）、流处理</li>
<li>编程不够灵活</li>
<li>不支持SQL语句，可以称其为分布式计算的编程语言</li>
</ul>
<h2 id="Spark背景：计算框架多样化"><a href="#Spark背景：计算框架多样化" class="headerlink" title="Spark背景：计算框架多样化"></a>Spark背景：计算框架多样化</h2><h4 id="现有的计算框架"><a href="#现有的计算框架" class="headerlink" title="现有的计算框架"></a>现有的计算框架</h4><ul>
<li>批处理：MapReduce、Hive、Spark…</li>
<li>流式计算：Storm</li>
<li>交互式计算：Impala、Presto</li>
<li>同时处理三种计算：<strong>Spark2.0</strong></li>
</ul>
<h2 id="Spark背景：什么是Spark"><a href="#Spark背景：什么是Spark" class="headerlink" title="Spark背景：什么是Spark"></a>Spark背景：什么是Spark</h2><h3 id="Spark："><a href="#Spark：" class="headerlink" title="Spark："></a>Spark：</h3><p>Spark是一个通用的、基于内存的<strong>并行计算</strong>框架。Spark也是基于<strong>MapReduce</strong>算法模式实现的分布式计算框架，并拥有Hadoop MapReduce的优点，解决了Hadoop MapReduce的诸多缺点。</p>
<h2 id="Spark生态系统："><a href="#Spark生态系统：" class="headerlink" title="Spark生态系统："></a>Spark生态系统：</h2><p>包含了Spark core、SparkSQL、Spark Streamimg、GraphX、MLlib、SparkR等子项目；<br>Spark支持Java、scala、Python、R、SQL语言；<br>Spark支持Standalone、Yarn、Mesos、K8s多种部署模式。<br><img alt="Spark生态系统" data-src="https://pic.superbed.cn/item/5d8cae10451253d178eb0712.png" class="lozad"></p>
<h3 id="Spark基本概念"><a href="#Spark基本概念" class="headerlink" title="Spark基本概念"></a>Spark基本概念</h3><h4 id="Spark-Core-Spark的核心功能实现"><a href="#Spark-Core-Spark的核心功能实现" class="headerlink" title="Spark Core : Spark的核心功能实现"></a>Spark Core : Spark的核心功能实现</h4><ul>
<li><strong>SparkContext</strong>： 通常而言，Driver Application的执行与输出都是通过SparkContext来完成的，在正式提交Application之前，首先需要初始化SparkContext。SparkContext内置的DAGScheduler负责创建Job,将DAG中的RDD划分到不同的stage,提交Stage等功能。内置的taskScheduler负责资源的申请、任务的提交及请求集群对任务的调度等工作。</li>
<li><strong>存储体系</strong>： Spark优先考虑使用各个节点的内存作为存储，当内存不足时才会考虑使用磁盘，使得Spark适用于实时计算、流式计算等场景。此外，Spark还提供了以内存为中心的高容错的分布式文件系统Alluxio供用户选择。Alluxio能够为Spark提供可靠的内存级文件共享服务。</li>
<li><strong>计算引擎</strong>： 计算引擎由SparkContext中的DAGScheduler、RDD以及具体节点上的Executor负责执行的Map和Reduce任务组成。DAGScheduler和RDD虽然位于SparkContext的内部，但是任务的正式提交与执行之前会将Job中的RDD组织成为有向无环图(建成DAG)，并对Stage进行划分，决定任务执行阶段的任务的数量、迭代计算、Shuffle等过程。</li>
<li><strong>部署模式</strong>： 由于单节点不足以提供足够的存储和计算能力，所以作为大数据处理的Spark在SparkContext的TaskScheduler的组件中提供了对Standalone部署模式的实现和在YARN、Mesos、k8s等分布式资源管理系统的支持。通过使用Standalone、YARN、Mesos等部署模式为Task分配计算资源，提供任务的并发执行效率。除了可用于生产环境的StandAlone、Yarn、Mesos、K8s等部署模式外，Spark还提供了Local模式和local-cluster模式便于我们开发和调试。</li>
</ul>
<h4 id="Spark-SQL："><a href="#Spark-SQL：" class="headerlink" title="Spark SQL："></a>Spark SQL：</h4><p>提供SQL的能力，便于熟悉关系型数据库操作的工程师进行交互查询。此外，还熟悉Hadoop的用户提供Hive SQL的处理能力。</p>
<h4 id="Spark-Streaming："><a href="#Spark-Streaming：" class="headerlink" title="Spark Streaming："></a>Spark Streaming：</h4><p>提供流式计算能力，支持Kafka、Flume、Twitter、MQTT、ZeroMQ、Kinesis和简单的TCP套接字等数据源。此外还提供窗口操作。</p>
<h4 id="GraphX："><a href="#GraphX：" class="headerlink" title="GraphX："></a>GraphX：</h4><p>提供图计算能力，支持分布式，Pregel提供的API可以解决图计算中的常见问题。</p>
<h4 id="MLlib："><a href="#MLlib：" class="headerlink" title="MLlib："></a>MLlib：</h4><p>提供机器学习相关的统计、分类、回归等领域的多种算法实现。其一致性的API接口大大降低了用户的学习成本。<br><strong>SparkSQL、Spark Streaming、GraphX、Mllib的能力都是建立在Spring Core之上。</strong></p>
<h2 id="计算类型及应用场景"><a href="#计算类型及应用场景" class="headerlink" title="计算类型及应用场景"></a>计算类型及应用场景</h2><ul>
<li>批处理计算：对时间没有严格要求，吞吐量高</li>
<li>迭代式与DAG计算：机器学习算法（DAG是有向无环图（Directed Acyclic Graph）的简称。在大数据处理中，DAG计算常常指的是将计算任务在内部分解成为若干个子任务，将这些子任务之间的逻辑关系或顺序构建成DAG（有向无环图）结构。）</li>
<li>交互式计算：支持类SQL语言，快速进行数据分析</li>
<li>流式计算：数据像流水一样流入进来，需实时对其处理分析</li>
</ul>
<h2 id="Spark特性-DAG"><a href="#Spark特性-DAG" class="headerlink" title="Spark特性-DAG"></a>Spark特性-DAG</h2><p><img alt="DAG" data-src="https://pic.superbed.cn/item/5d8cb4e9451253d178ed3cbe.png" class="lozad"></p>
<h2 id="Spark核心概念-RDD"><a href="#Spark核心概念-RDD" class="headerlink" title="Spark核心概念-RDD"></a>Spark核心概念-RDD</h2><h3 id="RDD：弹性分布式数据集-Resilient-Distributed-Datasets"><a href="#RDD：弹性分布式数据集-Resilient-Distributed-Datasets" class="headerlink" title="RDD：弹性分布式数据集(Resilient Distributed Datasets)"></a><u>RDD：弹性分布式数据集(Resilient Distributed Datasets)</u></h3><ul>
<li>RDD是Spark中计算和数据的抽象，它标识已经分片(partition),不可变的并能够被并行计算的数据集合。</li>
<li>RDD可以被存储在磁盘中也可以被存储到内存中。</li>
<li>RDD提供给我们很多方便的数据变换方法，这些变换操作分为两种类型（<strong>Transformation和Action</strong>）</li>
<li>RDD的生成方式有两种：数据源读入，其他RDD通过Transformation操作转换。</li>
<li>RDD失败后自动重构。<br><img alt="RDD组成" data-src="https://pic.superbed.cn/item/5d8cb67a451253d178edd238.png" class="lozad"></li>
<li>一个RDD由多个Partition构成(计算时一个partition对应一个task)。</li>
<li>每个Partion数据可以存储在内存中也可以存储在磁盘中(用户可控制)。</li>
<li>RDD的操作分为Trasformation和Action两种操作。</li>
</ul>
<h2 id="Spark核心概念-RDD基本操作"><a href="#Spark核心概念-RDD基本操作" class="headerlink" title="Spark核心概念-RDD基本操作"></a>Spark核心概念-RDD基本操作</h2><p><img alt="RDD基本操作" data-src="https://pic.superbed.cn/item/5d8cb8c1451253d178ee8918.png" class="lozad"></p>
<h3 id="Transformation："><a href="#Transformation：" class="headerlink" title="Transformation："></a>Transformation：</h3><p>把一个RDD转换为另外一个RDD。例如：map,filter,groupBy,reduceBy等。</p>
<h3 id="Action："><a href="#Action：" class="headerlink" title="Action："></a>Action：</h3><p>通过RDD计算得到一个或者一组值。例如：count</p>
<h3 id="WordCount-example"><a href="#WordCount-example" class="headerlink" title="WordCount example"></a>WordCount example</h3><p><img alt="WordCount" data-src="https://pic.superbed.cn/item/5d8cba22451253d178eefb7c.png" class="lozad"><br><strong>WordCount.java</strong></p>
<pre class=" language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>neu<span class="token punctuation">.</span>mapreduce<span class="token punctuation">;</span>

<span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span>
<span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>StringTokenizer<span class="token punctuation">;</span>

<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IntWritable<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>LongWritable<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Job<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Mapper<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Reducer<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileInputFormat<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>FileOutputFormat<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>partition<span class="token punctuation">.</span>HashPartitioner<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>util<span class="token punctuation">.</span>GenericOptionsParser<span class="token punctuation">;</span>

<span class="token keyword">import</span> com<span class="token punctuation">.</span>neu<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>util<span class="token punctuation">.</span>HDFSUtils<span class="token punctuation">;</span>

<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">WordCount</span> <span class="token punctuation">{</span>
    <span class="token comment" spellcheck="true">//继承mapper接口，设置map的输入类型为&lt;Object,Text></span>
    <span class="token comment" spellcheck="true">//输出类型为&lt;Text,IntWritable></span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">class</span> <span class="token class-name">Map</span> <span class="token keyword">extends</span> <span class="token class-name">Mapper</span><span class="token operator">&lt;</span>LongWritable<span class="token punctuation">,</span>Text<span class="token punctuation">,</span>Text<span class="token punctuation">,</span>IntWritable<span class="token operator">></span><span class="token punctuation">{</span>
        <span class="token comment" spellcheck="true">//one表示单词出现一次</span>
        <span class="token keyword">private</span> <span class="token keyword">static</span> IntWritable one <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">IntWritable</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment" spellcheck="true">//word存储切下的单词</span>
        <span class="token keyword">private</span> Text word <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Text</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">map</span><span class="token punctuation">(</span>LongWritable key<span class="token punctuation">,</span>Text value<span class="token punctuation">,</span>Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span>InterruptedException<span class="token punctuation">{</span>
            <span class="token comment" spellcheck="true">//对输入的行切词</span>
            StringTokenizer st <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">StringTokenizer</span><span class="token punctuation">(</span>value<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token keyword">while</span><span class="token punctuation">(</span>st<span class="token punctuation">.</span><span class="token function">hasMoreTokens</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>
                word<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>st<span class="token punctuation">.</span><span class="token function">nextToken</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//切下的单词存入word</span>
                context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>word<span class="token punctuation">,</span> one<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
    <span class="token comment" spellcheck="true">//继承reducer接口，设置reduce的输入类型&lt;Text,IntWritable></span>
    <span class="token comment" spellcheck="true">//输出类型为&lt;Text,IntWritable></span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">class</span> <span class="token class-name">Reduce</span> <span class="token keyword">extends</span> <span class="token class-name">Reducer</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span>IntWritable<span class="token punctuation">,</span>Text<span class="token punctuation">,</span>IntWritable<span class="token operator">></span><span class="token punctuation">{</span>
        <span class="token comment" spellcheck="true">//result记录单词的频数</span>
        <span class="token keyword">private</span> <span class="token keyword">static</span> IntWritable result <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">IntWritable</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">reduce</span><span class="token punctuation">(</span>Text key<span class="token punctuation">,</span>Iterable<span class="token operator">&lt;</span>IntWritable<span class="token operator">></span> values<span class="token punctuation">,</span>Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span>InterruptedException<span class="token punctuation">{</span>
            <span class="token keyword">int</span> sum <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
            <span class="token comment" spellcheck="true">//对获取的&lt;key,value-list>计算value的和</span>
            <span class="token keyword">for</span><span class="token punctuation">(</span>IntWritable val<span class="token operator">:</span>values<span class="token punctuation">)</span><span class="token punctuation">{</span>
                sum <span class="token operator">+=</span> val<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
            <span class="token comment" spellcheck="true">//将频数设置到result</span>
            result<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>sum<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token comment" spellcheck="true">//收集结果</span>
            context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> result<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>

    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">class</span> <span class="token class-name">WordPartitioner</span> <span class="token keyword">extends</span> <span class="token class-name">HashPartitioner</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> IntWritable<span class="token operator">></span> <span class="token punctuation">{</span>

        <span class="token annotation punctuation">@Override</span>
        <span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">getPartition</span><span class="token punctuation">(</span>Text key<span class="token punctuation">,</span> IntWritable value<span class="token punctuation">,</span> <span class="token keyword">int</span> numReduceTasks<span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token keyword">if</span><span class="token punctuation">(</span>key<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Text</span><span class="token punctuation">(</span><span class="token string">"Bootstrap"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
                <span class="token keyword">return</span> <span class="token number">2</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
            <span class="token keyword">return</span> <span class="token keyword">super</span><span class="token punctuation">.</span><span class="token function">getPartition</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> value<span class="token punctuation">,</span> numReduceTasks <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
    <span class="token comment" spellcheck="true">/**
     * @param args
     */</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception<span class="token punctuation">{</span>
        Configuration conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment" spellcheck="true">//conf.set("mapreduce.output.fileoutputformat.compress", "true");</span>
        <span class="token comment" spellcheck="true">//conf.set("mapreduce.job.queuename ", "spark");</span>
        <span class="token comment" spellcheck="true">//检查运行命令</span>
        String<span class="token punctuation">[</span><span class="token punctuation">]</span> otherArgs <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">GenericOptionsParser</span><span class="token punctuation">(</span>conf<span class="token punctuation">,</span>args<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getRemainingArgs</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">if</span><span class="token punctuation">(</span>otherArgs<span class="token punctuation">.</span>length <span class="token operator">!=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">{</span>
            System<span class="token punctuation">.</span>err<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"Usage WordCount &lt;int> &lt;out>"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            System<span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
        HDFSUtils hdfs <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">HDFSUtils</span><span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">;</span>
        hdfs<span class="token punctuation">.</span><span class="token function">deleteDir</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment" spellcheck="true">//配置作业名</span>
        Job job <span class="token operator">=</span> Job<span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>conf<span class="token punctuation">,</span> <span class="token string">"word count"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment" spellcheck="true">//配置作业各个类</span>
        job<span class="token punctuation">.</span><span class="token function">setJarByClass</span><span class="token punctuation">(</span>WordCount<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        job<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span>Map<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        job<span class="token punctuation">.</span><span class="token function">setMapOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        job<span class="token punctuation">.</span><span class="token function">setMapOutputValueClass</span><span class="token punctuation">(</span>IntWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment" spellcheck="true">//      job.setCombinerClass(Reduce.class);</span>
        job<span class="token punctuation">.</span><span class="token function">setReducerClass</span><span class="token punctuation">(</span>Reduce<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        job<span class="token punctuation">.</span><span class="token function">setOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        job<span class="token punctuation">.</span><span class="token function">setOutputValueClass</span><span class="token punctuation">(</span>IntWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        job<span class="token punctuation">.</span><span class="token function">setNumReduceTasks</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment" spellcheck="true">//      job.setPartitionerClass(WordPartitioner.class);</span>
        FileInputFormat<span class="token punctuation">.</span><span class="token function">addInputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment" spellcheck="true">//      FileInputFormat.setMaxInputSplitSize(job, 10);</span>
<span class="token comment" spellcheck="true">//      FileInputFormat.setMinInputSplitSize(job, 10);</span>
        FileOutputFormat<span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment" spellcheck="true">//      FileOutputFormat.setCompressOutput(job, true);</span>
<span class="token comment" spellcheck="true">//      FileOutputFormat.setOutputCompressorClass(job, BZip2Codec.class);</span>
        System<span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span>job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token operator">?</span> <span class="token number">0</span> <span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

<span class="token punctuation">}</span></code></pre>
<p><strong>WordCount_Spark.java</strong></p>
<pre class=" language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>neu<span class="token punctuation">;</span>
<span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>ArrayList<span class="token punctuation">;</span>
<span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Iterator<span class="token punctuation">;</span>
<span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>List<span class="token punctuation">;</span>
<span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Map<span class="token punctuation">;</span>

<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>log4j<span class="token punctuation">.</span>Logger<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>SparkConf<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>SparkContext<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span>JavaPairRDD<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span>JavaRDD<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span>JavaSparkContext<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span>function<span class="token punctuation">.</span>FlatMapFunction<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span>function<span class="token punctuation">.</span>Function2<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span>function<span class="token punctuation">.</span>PairFunction<span class="token punctuation">;</span>

<span class="token keyword">import</span> scala<span class="token punctuation">.</span>Tuple2<span class="token punctuation">;</span>


<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">WordCount</span> <span class="token punctuation">{</span>

    <span class="token keyword">private</span> <span class="token keyword">static</span> Logger log <span class="token operator">=</span> Logger<span class="token punctuation">.</span><span class="token function">getLogger</span><span class="token punctuation">(</span>WordCount<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token annotation punctuation">@SuppressWarnings</span><span class="token punctuation">(</span><span class="token string">"resource"</span><span class="token punctuation">)</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        log<span class="token punctuation">.</span><span class="token function">info</span><span class="token punctuation">(</span><span class="token string">"开始执行wordcount!"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">try</span> <span class="token punctuation">{</span>
            SparkConf conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">SparkConf</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            conf<span class="token punctuation">.</span><span class="token function">setAppName</span><span class="token punctuation">(</span><span class="token string">"wordCount"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            conf<span class="token punctuation">.</span><span class="token function">setMaster</span><span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            SparkContext sc <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">SparkContext</span><span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">;</span>
            JavaSparkContext jsc <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">JavaSparkContext</span><span class="token punctuation">(</span>sc<span class="token punctuation">)</span><span class="token punctuation">;</span>

            log<span class="token punctuation">.</span><span class="token function">info</span><span class="token punctuation">(</span><span class="token string">"开始读取数据!"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            JavaRDD<span class="token operator">&lt;</span>String<span class="token operator">></span> data <span class="token operator">=</span> jsc<span class="token punctuation">.</span><span class="token function">textFile</span><span class="token punctuation">(</span><span class="token string">"file:///D:\\test.txt"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            log<span class="token punctuation">.</span><span class="token function">info</span><span class="token punctuation">(</span><span class="token string">"结束读取数据"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

            JavaRDD<span class="token operator">&lt;</span>String<span class="token operator">></span> wordRDD <span class="token operator">=</span> data<span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">FlatMapFunction</span><span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>

                <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">long</span> serialVersionUID <span class="token operator">=</span> <span class="token operator">-</span>294828459740757725L<span class="token punctuation">;</span>

                <span class="token keyword">public</span> Iterator<span class="token operator">&lt;</span>String<span class="token operator">></span> <span class="token function">call</span><span class="token punctuation">(</span>String t<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>
                    String<span class="token punctuation">[</span><span class="token punctuation">]</span> words <span class="token operator">=</span> t<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    List<span class="token operator">&lt;</span>String<span class="token operator">></span> list <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token operator">&lt;</span>String<span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> words<span class="token punctuation">.</span>length<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
                        list<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span>words<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token punctuation">}</span>
                    <span class="token keyword">return</span> list<span class="token punctuation">.</span><span class="token function">iterator</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token punctuation">}</span>
            <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>


            JavaPairRDD<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Integer<span class="token operator">></span> wordPairRDD <span class="token operator">=</span> wordRDD<span class="token punctuation">.</span><span class="token function">mapToPair</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">PairFunction</span><span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token punctuation">,</span> Integer<span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>

                <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">long</span> serialVersionUID <span class="token operator">=</span> <span class="token operator">-</span>3940041647950913972L<span class="token punctuation">;</span>

                <span class="token keyword">public</span> Tuple2<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Integer<span class="token operator">></span> <span class="token function">call</span><span class="token punctuation">(</span>String t<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>
                    <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">Tuple2</span><span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Integer<span class="token operator">></span><span class="token punctuation">(</span>t<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token punctuation">}</span>
            <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

            JavaPairRDD<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Integer<span class="token operator">></span> wordCountRS <span class="token operator">=</span> wordPairRDD<span class="token punctuation">.</span><span class="token function">reduceByKey</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Function2</span><span class="token operator">&lt;</span>Integer<span class="token punctuation">,</span> Integer<span class="token punctuation">,</span> Integer<span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>

                <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">long</span> serialVersionUID <span class="token operator">=</span> 1254368307373180066L<span class="token punctuation">;</span>

                <span class="token keyword">public</span> Integer <span class="token function">call</span><span class="token punctuation">(</span>Integer v1<span class="token punctuation">,</span> Integer v2<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>
                    <span class="token keyword">return</span> v1<span class="token punctuation">.</span><span class="token function">intValue</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> v2<span class="token punctuation">.</span><span class="token function">intValue</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token punctuation">}</span>
            <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

            Map<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Integer<span class="token operator">></span> result <span class="token operator">=</span> wordCountRS<span class="token punctuation">.</span><span class="token function">collectAsMap</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

            System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>result<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>data<span class="token punctuation">.</span><span class="token function">count</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            log<span class="token punctuation">.</span><span class="token function">info</span><span class="token punctuation">(</span><span class="token string">"数据条数："</span> <span class="token operator">+</span> data<span class="token punctuation">.</span><span class="token function">count</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            log<span class="token punctuation">.</span><span class="token function">info</span><span class="token punctuation">(</span><span class="token string">"开始输出文件:D:\\output"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            wordCountRS<span class="token punctuation">.</span><span class="token function">saveAsTextFile</span><span class="token punctuation">(</span><span class="token string">"D:\\output"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            log<span class="token punctuation">.</span><span class="token function">info</span><span class="token punctuation">(</span><span class="token string">"结束输出文件D:\\output"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            log<span class="token punctuation">.</span><span class="token function">info</span><span class="token punctuation">(</span><span class="token string">"结束执行wordcount程序！"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>
            log<span class="token punctuation">.</span><span class="token function">error</span><span class="token punctuation">(</span><span class="token string">"执行失败"</span><span class="token punctuation">,</span>e<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>

    <span class="token punctuation">}</span>

<span class="token punctuation">}</span></code></pre>
<h2 id="Spark核心概念-RDD的缓存位置"><a href="#Spark核心概念-RDD的缓存位置" class="headerlink" title="Spark核心概念-RDD的缓存位置"></a>Spark核心概念-RDD的缓存位置</h2><p>RDD既可以存储为内存中也可以存储在磁盘里面。Spark为我们提供了一下几种方案。</p>
<ul>
<li>MEMORY_ONLY:将RDD 作为反序列化的的对象存储JVM 中。如果RDD不能被内存装下，一些分区将不会被缓存，并且在需要的时候被重新计算。<br>这是是默认的级别</li>
<li>MEMORY_AND_DISK:将RDD 作为反序列化的的对象存储在JVM 中。如果RDD不能被与内存装下，超出的分区将被保存在硬盘上，并且在需要时被读取</li>
<li>MEMORY_ONLY_SER:将RDD 作为序列化的的对象进行存储（每一分区占用一个字节数组）。<br>通常来说，这比将对象反序列化的空间利用率更高，尤其当使用fast serializer,但在读取时会比较占用CPU</li>
<li>MEMORY_AND_DISK_SER:与MEMORY_ONLY_SER 相似，但是把超出内存的分区将存储在硬盘上而不是在每次需要的时候重新计算</li>
<li>DISK_ONLY:只将RDD 分区存储在硬盘上</li>
<li>MEMORY_ONLY_2:与上述的存储级别一样，但是将每一个分区都被复制两份存储在集群结点上</li>
</ul>
<p>用户可以根据RDD提供的方法选择缓存方案:</p>
<pre class=" language-java"><code class="language-java">JavaRDD<span class="token operator">&lt;</span>String<span class="token operator">></span> data <span class="token operator">=</span> jsc<span class="token punctuation">.</span> <span class="token function">textFile</span><span class="token punctuation">(</span><span class="token string">"/data/external/dataCompletion/2017-05-11/cp_86.1000.11_20170605. csv"</span><span class="token punctuation">)</span><span class="token punctuation">;</span> data<span class="token punctuation">.</span> <span class="token function">cache</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> 
data<span class="token punctuation">.</span> <span class="token function">persist</span><span class="token punctuation">(</span>StorageLeve1<span class="token punctuation">.</span> <span class="token function">MEMORY_AND_DISK</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
val NONE<span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Storagelevel</span><span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span>
val DISK_ONLY <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">StorageLevel</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span>
val DISK_ONLY_2<span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Storagelevel</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>
val MEMORY_ONLY <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Storagelevel</span><span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span>
val MEMORY_ONLY_2<span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Storagelevel</span><span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>
val MEMORY_ONLY_SER <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Storagelevel</span><span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span>
val MEMORY_ONLY _SER_2<span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Storagelevel</span><span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>
val MEMORY_AND_DISK <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Storagelevel</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span>
val MEMORY_AND_DISK_2<span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Storagelevel</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>
val MEMORY_AND_DISK_SER <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">StorageLevel</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span>
val MEMORY_AND_DISK_SER_2<span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Storagelevel</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>
val OFF_HEAP <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Storagelevel</span><span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span></code></pre>
<h2 id="Spark基本架构"><a href="#Spark基本架构" class="headerlink" title="Spark基本架构"></a>Spark基本架构</h2><p><img alt="Spark基本架构" data-src="https://pic.superbed.cn/item/5d8cbc4a451253d178efa11e.png" class="lozad"></p>
<h3 id="Cluster-Manager："><a href="#Cluster-Manager：" class="headerlink" title="Cluster Manager："></a>Cluster Manager：</h3><p>Spark集群管理器，主要负责资源的分配和管理。集群管理器分配的资源属于一级分配，它将各个Worker上的内存、CPU等资源分配给应用程序，但是并不负责Executor的资源分配。目前，Standalone、Yarn、Mesos、EC2等都可作为Spark的集群管理器。</p>
<h3 id="Driver-Programe："><a href="#Driver-Programe：" class="headerlink" title="Driver Programe："></a>Driver Programe：</h3><p>客户端驱动程序，也可理解为客户端应用程序，用于将任务程序转换为RDD和DAG，并与Cluster Manager进行通信与调度。</p>
<h3 id="Worker-Node："><a href="#Worker-Node：" class="headerlink" title="Worker Node："></a>Worker Node：</h3><p>Spark的工作节点。对于Spark应用程序来说，由集群管理器分配得到的资源的Work节点主要负责以下工作：创建Executor，将资源和任务进一步分配给Executor，同步资源信息给Cluster Manager。</p>
<h3 id="Executor"><a href="#Executor" class="headerlink" title="Executor:"></a>Executor:</h3><p>执行计算任务的一线进程。主要负责任务的执行以及Worker、Driver Program的信息同步。每个应用程序都有自己的executor。每个excutor包含多个task。</p>
<h2 id="Spark运行模式"><a href="#Spark运行模式" class="headerlink" title="Spark运行模式"></a>Spark运行模式</h2><h3 id="Local模式："><a href="#Local模式：" class="headerlink" title="Local模式："></a>Local模式：</h3><p>单机运行，通常用于测试。</p>
<h3 id="Standalone模式："><a href="#Standalone模式：" class="headerlink" title="Standalone模式："></a>Standalone模式：</h3><p>独立运行在一个spark的集群中。</p>
<h3 id="Spark-On-Yarn-Mesos模式："><a href="#Spark-On-Yarn-Mesos模式：" class="headerlink" title="Spark On Yarn/Mesos模式："></a>Spark On Yarn/Mesos模式：</h3><p>Spark程序运行在资源管理器上，例如YARN/Mesos<br>Spark on Yarn存在两种模式：<br>    1.yarn-client <img alt="Client" data-src="https://pic.superbed.cn/item/5d8cbe53451253d178f02f67.png" class="lozad"><br>    2.yarn-cluster <img alt="Cluster" data-src="https://pic.superbed.cn/item/5d8cbe4f451253d178f02de6.png" class="lozad"><br><img alt="Spark运行模式" data-src="https://pic.superbed.cn/item/5d8cbd69451253d178eff7fa.png" class="lozad"></p>
<ul>
<li>Application Master:在YARN中，每个Application实例都有一个Application Master进程，它是Application启动的第一个容器。它负责和ResourceManager打交道，并请求资源。获取资源之后告诉NodeManager为其启动container。</li>
<li>一个Application实例对应一个Application Master进程，也是运行在一个YARN Container中，并且是第一个Container。</li>
<li>Application Master只负责从Resource Manager处获取资源。由Client与各个Container进行通信确认如何工作。</li>
</ul>
<p><img alt="Spark运行模式-1" data-src="https://pic.superbed.cn/item/5d8cbdd3451253d178f01157.png" class="lozad"><br>yarn-cluster和yarn-client模式的区别其实就是Application Master进程的区别，yarn-cluster模式下，driver运行在AM(Application Master)中，它负责向YARN申请资源，并监督作业的运行状况。当用户提交了作业之后，就可以关掉Client，作业会继续在YARN上运行。然而yarn-cluster模式不适合运行交互类型的作业。而yarn-client模式下，Application Master仅仅向YARN请求executor，client会和请求的container通信来调度他们工作，也就是说Client不能离开。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script></div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">zheroic</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://zheroic.github.io/2019/09/26/spark-1/">https://zheroic.github.io/2019/09/26/spark-1/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://zheroic.github.io">zh小企鹅</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/spark/">spark    </a></div><div class="post_share"><div class="social-share" data-image="https://pic.superbed.cn/item/5d8c9264451253d178e2de72.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script></div></div><nav class="pagination_post" id="pagination"><div class="prev-post pull-left"><a href="/2019/09/27/hadoop-1/"><img class="prev_cover lozad" data-src="https://pic.superbed.cn/item/5d8d569d451253d1782f0d92.png" onerror="onerror=null;src='/img/404.jpg'"><div class="label">上一篇</div><div class="prev_info"><span>hadoop离线计算-1:初识Hadoop</span></div></a></div><div class="next-post pull-right"><a href="/2019/09/25/software-requirement-2/"><img class="next_cover lozad" data-src="https://pic.superbed.cn/item/5d7b0e77451253d178a768fe.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="label">下一篇</div><div class="next_info"><span>软件需求分析设计-2</span></div></a></div></nav><hr><div id="post-comment"><div class="comment_headling"><i class="fa fa-comments fa-fw" aria-hidden="true"></i><span> 评论</span></div><div id="gitalk-container"></div><script>var gitalk = new Gitalk({
  clientID: '3875e95f58ea59855e05',
  clientSecret: '335bf09bc36a5dae2109909b8b305e96c7966880',
  repo: 'zheroic.github.io',
  owner: 'zheroic',
  admin: 'zheroic',
  id: md5(decodeURI(location.pathname)),
  language: 'zh-CN'
})
gitalk.render('gitalk-container')</script></div></div></div><footer><div id="footer"><div class="copyright">&copy;2019 By zheroic</div><div class="framework-info"><span>驱动 </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly"><span>Butterfly</span></a></div><div class="footer_custom_text">Hi, welcome to my <a href="https://zheroic.github.io/">blog</a>!</div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><section class="rightside" id="rightside"><a id="to_comment" href="#post-comment"><i class="scroll_to_comment fa fa-comments"></i></a><i class="fa fa-book" id="readmode" title="阅读模式"> </i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换">繁</a><i class="nightshift fa fa-moon-o" id="nightshift" title="夜间模式"></i></section><div class=" " id="post_bottom"><div id="post_bottom_items"><a id="mobile_to_comment" href="#post-comment"><i class="mobile_scroll_to_comment fa fa-comments"></i></a><i class="fa fa-list" id="mobile_toc"></i><div id="toc_mobile"><div class="toc_mobile_headline">目录</div><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#初识Spark"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text">初识Spark</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#大数据技术框架"><span class="toc_mobile_items-number">1.1.</span> <span class="toc_mobile_items-text">大数据技术框架</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Spark背景-HDFS"><span class="toc_mobile_items-number">1.2.</span> <span class="toc_mobile_items-text">Spark背景-HDFS</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#官方定义："><span class="toc_mobile_items-number">1.2.1.</span> <span class="toc_mobile_items-text">官方定义：</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#基本原理："><span class="toc_mobile_items-number">1.2.2.</span> <span class="toc_mobile_items-text">基本原理：</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#优点："><span class="toc_mobile_items-number">1.2.3.</span> <span class="toc_mobile_items-text">优点：</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#缺点："><span class="toc_mobile_items-number">1.2.4.</span> <span class="toc_mobile_items-text">缺点：</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Spark背景-资源调度"><span class="toc_mobile_items-number">1.3.</span> <span class="toc_mobile_items-text">Spark背景-资源调度</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Spark背景-Mapreduce"><span class="toc_mobile_items-number">1.4.</span> <span class="toc_mobile_items-text">Spark背景-Mapreduce</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#为什么需要？"><span class="toc_mobile_items-number">1.4.1.</span> <span class="toc_mobile_items-text">为什么需要？</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#大规模数据处理时，MapReduce在三个层次上的基本构思："><span class="toc_mobile_items-number">1.4.2.</span> <span class="toc_mobile_items-text">大规模数据处理时，MapReduce在三个层次上的基本构思：</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#结论："><span class="toc_mobile_items-number">1.4.3.</span> <span class="toc_mobile_items-text">结论：</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#Map"><span class="toc_mobile_items-number">1.4.4.</span> <span class="toc_mobile_items-text">Map</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#Reduce"><span class="toc_mobile_items-number">1.4.5.</span> <span class="toc_mobile_items-text">Reduce</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#局限性"><span class="toc_mobile_items-number">1.4.6.</span> <span class="toc_mobile_items-text">局限性</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Spark背景：计算框架多样化"><span class="toc_mobile_items-number">1.5.</span> <span class="toc_mobile_items-text">Spark背景：计算框架多样化</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#现有的计算框架"><span class="toc_mobile_items-number">1.5.0.1.</span> <span class="toc_mobile_items-text">现有的计算框架</span></a></li></ol></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Spark背景：什么是Spark"><span class="toc_mobile_items-number">1.6.</span> <span class="toc_mobile_items-text">Spark背景：什么是Spark</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#Spark："><span class="toc_mobile_items-number">1.6.1.</span> <span class="toc_mobile_items-text">Spark：</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Spark生态系统："><span class="toc_mobile_items-number">1.7.</span> <span class="toc_mobile_items-text">Spark生态系统：</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#Spark基本概念"><span class="toc_mobile_items-number">1.7.1.</span> <span class="toc_mobile_items-text">Spark基本概念</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#Spark-Core-Spark的核心功能实现"><span class="toc_mobile_items-number">1.7.1.1.</span> <span class="toc_mobile_items-text">Spark Core : Spark的核心功能实现</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#Spark-SQL："><span class="toc_mobile_items-number">1.7.1.2.</span> <span class="toc_mobile_items-text">Spark SQL：</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#Spark-Streaming："><span class="toc_mobile_items-number">1.7.1.3.</span> <span class="toc_mobile_items-text">Spark Streaming：</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#GraphX："><span class="toc_mobile_items-number">1.7.1.4.</span> <span class="toc_mobile_items-text">GraphX：</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#MLlib："><span class="toc_mobile_items-number">1.7.1.5.</span> <span class="toc_mobile_items-text">MLlib：</span></a></li></ol></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#计算类型及应用场景"><span class="toc_mobile_items-number">1.8.</span> <span class="toc_mobile_items-text">计算类型及应用场景</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Spark特性-DAG"><span class="toc_mobile_items-number">1.9.</span> <span class="toc_mobile_items-text">Spark特性-DAG</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Spark核心概念-RDD"><span class="toc_mobile_items-number">1.10.</span> <span class="toc_mobile_items-text">Spark核心概念-RDD</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#RDD：弹性分布式数据集-Resilient-Distributed-Datasets"><span class="toc_mobile_items-number">1.10.1.</span> <span class="toc_mobile_items-text">RDD：弹性分布式数据集(Resilient Distributed Datasets)</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Spark核心概念-RDD基本操作"><span class="toc_mobile_items-number">1.11.</span> <span class="toc_mobile_items-text">Spark核心概念-RDD基本操作</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#Transformation："><span class="toc_mobile_items-number">1.11.1.</span> <span class="toc_mobile_items-text">Transformation：</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#Action："><span class="toc_mobile_items-number">1.11.2.</span> <span class="toc_mobile_items-text">Action：</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#WordCount-example"><span class="toc_mobile_items-number">1.11.3.</span> <span class="toc_mobile_items-text">WordCount example</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Spark核心概念-RDD的缓存位置"><span class="toc_mobile_items-number">1.12.</span> <span class="toc_mobile_items-text">Spark核心概念-RDD的缓存位置</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Spark基本架构"><span class="toc_mobile_items-number">1.13.</span> <span class="toc_mobile_items-text">Spark基本架构</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#Cluster-Manager："><span class="toc_mobile_items-number">1.13.1.</span> <span class="toc_mobile_items-text">Cluster Manager：</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#Driver-Programe："><span class="toc_mobile_items-number">1.13.2.</span> <span class="toc_mobile_items-text">Driver Programe：</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#Worker-Node："><span class="toc_mobile_items-number">1.13.3.</span> <span class="toc_mobile_items-text">Worker Node：</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#Executor"><span class="toc_mobile_items-number">1.13.4.</span> <span class="toc_mobile_items-text">Executor:</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Spark运行模式"><span class="toc_mobile_items-number">1.14.</span> <span class="toc_mobile_items-text">Spark运行模式</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#Local模式："><span class="toc_mobile_items-number">1.14.1.</span> <span class="toc_mobile_items-text">Local模式：</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#Standalone模式："><span class="toc_mobile_items-number">1.14.2.</span> <span class="toc_mobile_items-text">Standalone模式：</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#Spark-On-Yarn-Mesos模式："><span class="toc_mobile_items-number">1.14.3.</span> <span class="toc_mobile_items-text">Spark On Yarn/Mesos模式：</span></a></li></ol></li></ol></div></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script async src="/js/search/local-search.js"></script><script src="/js/nightshift.js"></script><script src="/js/tw_cn.js"></script><script>translateInitilization()

</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@1.2.2/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script><script>const observer = lozad(); // lazy loads elements with default selector as '.lozad'
observer.observe();</script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>